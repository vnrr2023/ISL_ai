{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc7db4a-d175-46a5-a9bc-ac43da7fa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data collection code here for ISL.ai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c50bd86-768b-4f50-978d-ad30b29d9761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb662d6-ec60-4fb9-9998-98835eae2acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "\n",
    "    cv.imshow('frame',frame)\n",
    "    if cv.waitKey(10)==27:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a861ea1-5f5c-4892-8363-ca6ebad06d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_holistic=mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38df63e-2b8c-498d-9f97-1458338be2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "holistic=mp_holistic.Holistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872034d3-092c-498e-a7a4-fc4da89a407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.mp4',\n",
       " '1.mp4',\n",
       " '10.mp4',\n",
       " '11.mp4',\n",
       " '12.mp4',\n",
       " '13.mp4',\n",
       " '14.mp4',\n",
       " '2.mp4',\n",
       " '3.mp4',\n",
       " '4.mp4',\n",
       " '5.mp4',\n",
       " '6.mp4',\n",
       " '7.mp4',\n",
       " '8.mp4',\n",
       " '9.mp4']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('videos//b/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d25a9b44-3b7f-423d-beb9-c1edb03ab838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.57852816581726\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "for i in os.listdir('videos//c/')[:5]:\n",
    "    cap=cv.VideoCapture(f'videos//c/{i}')\n",
    "\n",
    "    for frame_idx in range(int(cap.get(cv.CAP_PROP_FRAME_COUNT))):\n",
    "        _,frame=cap.read()\n",
    "        # mediapipe operations\n",
    "        img=cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "        results=holistic.process(img)\n",
    "        img=cv.cvtColor(img,cv.COLOR_RGB2BGR)\n",
    "        draw_landmarks(img,results)\n",
    "        \n",
    "        cv.imshow('frame',img)\n",
    "        if cv.waitKey(1)==27:\n",
    "            cap.release()\n",
    "            break\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(time()-start)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ba060d-56a0-480d-9ea1-b06eb7b1d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img,results):\n",
    "    mp_drawing.draw_landmarks(img,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,style1,style2)\n",
    "    mp_drawing.draw_landmarks(img,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,style1,style2)\n",
    "    mp_drawing.draw_landmarks(img,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,style1,style2)\n",
    "    mp_drawing.draw_landmarks(img,results.face_landmarks,mp_holistic.FACEMESH_CONTOURS,style1,style2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ada72c6-02c3-42d6-bc5f-942d83c72f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "style1=mp_drawing.DrawingSpec((71, 237, 212),1,1)\n",
    "style2=mp_drawing.DrawingSpec((67, 73, 247),2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202a0f5a-893b-4420-a18e-1cf6b9e36c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48625db6-5d81-4f52-ae83-e0523c86415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(results):\n",
    "    face=np.array([[landmark.x,landmark.y,landmark.z] for landmark in results.face_landmarks.landmark]).flatten()  if results.face_landmarks else np.zeros(1404)\n",
    "    pose=np.array([[landmark.x,landmark.y,landmark.z , landmark.visibility] for landmark in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    rh=np.array([[landmark.x,landmark.y,landmark.z] for landmark in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(63)\n",
    "    lh=np.array([[landmark.x,landmark.y,landmark.z] for landmark in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(63)\n",
    "\n",
    "    return np.concatenate([pose,face,lh,rh]),np.concatenate([pose,lh,rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63697c-e737-4072-aefb-52c56704d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.pose_landmarks.landmark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a166e6a0-a70e-4282-9bac-4d5aebb677be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 480\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek chouhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "cap=cv.VideoCapture(0)\n",
    "# get the properties of the captured frames\n",
    "width=int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "fps=int(cap.get(cv.CAP_PROP_FPS))\n",
    "print(width,height)\n",
    "# writer=cv.VideoWriter(\n",
    "#     os.path.join('videos',f'test.mp4'),\n",
    "#     cv.VideoWriter_fourcc(*'DIVX'),\n",
    "#     fps,\n",
    "#     (height,width)\n",
    "# )\n",
    "\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv.VideoWriter(os.path.join(video_dir,action,'output.mp4'),\n",
    "                fourcc, \n",
    "                fps,\n",
    "                (640,480)\n",
    "                )\n",
    "\n",
    "while True:\n",
    "    _,frame=cap.read()\n",
    "    print(frame.shape)\n",
    "    # mediapipe operations\n",
    "    img=cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "    results=holistic.process(img)\n",
    "    img=cv.cvtColor(img,cv.COLOR_RGB2BGR)\n",
    "    draw_landmarks(img,results)\n",
    "    landmarks=extract_landmarks(results)\n",
    "    # print(landmarks)\n",
    "    video_writer.write(frame)\n",
    "    cv.imshow('frame',img)\n",
    "    if cv.waitKey(1)==27:\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "video_writer.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f50a5329-cadf-400b-b7d6-94fd12a94348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "674798e2-dedd-41da-841f-3014789fc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir30='alpha_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b22cce8-d169-4557-9473-8d97332a7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir15='alpha_15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b982820a-e934-411a-bc12-aed105678277",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir='videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7579bd51-7943-43f4-b892-d430bd5d20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_videos=150\n",
    "no_of_frames=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce15d5af-70ea-49d3-895b-872927428d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "action='z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecae2845-ec73-46c7-9072-1d49d110b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(data_dir30,action))\n",
    "os.mkdir(os.path.join(data_dir15,action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac29fef1-fb19-49b5-8e70-6b842cc9cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(video_dir,action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8329d73d-653b-4e19-94d9-8315f55000c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no_of_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# for action in actions:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     print(action)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mno_of_videos\u001b[49m):\n\u001b[0;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir,action,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'no_of_videos' is not defined"
     ]
    }
   ],
   "source": [
    "# for action in actions:\n",
    "#     print(action)\n",
    "for video in range(no_of_videos):\n",
    "    os.makedirs(os.path.join(data_dir,action,f'{video}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0b9470-4a7d-472d-8522-be935806627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "283846b7-2c3f-4a66-be21-467a4503a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.87968182563782\n"
     ]
    }
   ],
   "source": [
    "st=time()\n",
    "try:\n",
    "    cap=cv.VideoCapture(0)\n",
    "\n",
    "    # get the properties of the captured frames\n",
    "    width=int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height=int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps=cap.get(cv.CAP_PROP_FPS)\n",
    "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    " \n",
    "    \n",
    "    for video in range(5):\n",
    "    # for video in [15,69,70,78,79,144]:\n",
    "        l_list=[]\n",
    "        alpha_list=[]\n",
    "       \n",
    "        video_writer = cv.VideoWriter(os.path.join(video_dir,action,f'{video}.mp4'),\n",
    "                fourcc, \n",
    "                30,\n",
    "                (640,480)\n",
    "                )\n",
    "        start=time()\n",
    "        for frame in range(no_of_frames):\n",
    "            _,framee=cap.read()\n",
    "            fps=cap.get(cv.CAP_PROP_FPS)\n",
    "            \n",
    "            # mediapipe operations\n",
    "            img=cv.cvtColor(framee,cv.COLOR_BGR2RGB)\n",
    "            results=holistic.process(img)\n",
    "            img=cv.cvtColor(img,cv.COLOR_RGB2BGR)\n",
    "          \n",
    "            draw_landmarks(img,results)\n",
    "          \n",
    "            landmarks=extract_landmarks(results)\n",
    "            if frame==0:  # for the first frame\n",
    "                cv.putText(img,f'Starting collection',(100,200),cv.FONT_HERSHEY_COMPLEX_SMALL,4,(0,0,255),1,cv.LINE_AA)\n",
    "                cv.putText(img,f'For {action}  Video {video} Frame {frame}',(120,32),cv.FONT_HERSHEY_COMPLEX_SMALL,1,(255,0,0),1,cv.LINE_AA)\n",
    "                cv.imshow('image',img)\n",
    "                cv.waitKey(4000)\n",
    "            else:\n",
    "                cv.putText(img,f'For {action}  Video {video} Frame {frame}',(120,32),cv.FONT_HERSHEY_COMPLEX_SMALL,1,(255,0,0),1,cv.LINE_AA)\n",
    "               \n",
    "                cv.imshow('image',img)\n",
    "            video_writer.write(framee)\n",
    "    \n",
    "            # path=os.path.join(data_dir,action,str(video),f'{frame}.npy')\n",
    "            # np.save(path,landmarks)\n",
    "            l_list.append(landmarks[0])\n",
    "            alpha_list.append(landmarks[1])\n",
    "           \n",
    "    \n",
    "            \n",
    "        \n",
    "            \n",
    "            if cv.waitKey(1)==27:\n",
    "                cap.release()\n",
    "                break\n",
    "          \n",
    "        video_writer.release()   \n",
    "        # create numpy arrays\n",
    "        array_for_30=np.array(l_list)\n",
    "        array_for_15=np.array(alpha_list)\n",
    "    \n",
    "        # clear the lists/empty them\n",
    "        l_list.clear()\n",
    "        alpha_list.clear()\n",
    "    \n",
    "        # create paths\n",
    "        path_for_alpha_30=os.path.join(data_dir30,action,f'{video}.npy')\n",
    "        path_for_alpha_15_1=os.path.join(data_dir15,action,f'{video}.npy')\n",
    "        path_for_alpha_15_2=os.path.join(data_dir15,action,f'{video+500}.npy')\n",
    "        \n",
    "        # np.save(path_for_alpha_30,array_for_30)\n",
    "        # np.save(path_for_alpha_15_1,array_for_15[:15])\n",
    "        # np.save(path_for_alpha_15_2,array_for_15[15:])\n",
    "        # print(array_for_15.shape)\n",
    "            \n",
    "except:\n",
    "        print('error')\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "print(time()-st)    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06553265-ca0a-4980-b843-9554bbd8b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    " video_writer.release()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab483fe-a0ba-4724-be97-49227c0d2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello\n",
    "thank you\n",
    "# please\n",
    "how are you\n",
    "i am fine\n",
    "i am not well\n",
    "blank\n",
    "morning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00554a34-bff2-4b05-ad8a-1eb82be251c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f859cdc-adaf-4714-89f1-4a8cc57200df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089854b-e9f1-4e80-9542-fbfe27d37905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

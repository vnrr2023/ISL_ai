{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693372fb-80fe-4033-974f-0236e74b6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here after collecting the data create the code for implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f37615-db37-4311-a8fd-dc330ea77595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1026c421-2290-45e9-84c5-7fc5cb061272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='../temp'\n",
    "no_of_videos=150\n",
    "no_of_frames=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9908eedd-cb32-4628-9eb3-165c4dcf62de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afternoon',\n",
       " 'blank',\n",
       " 'evening',\n",
       " 'fine',\n",
       " 'hello',\n",
       " 'how are you',\n",
       " 'morning',\n",
       " 'name',\n",
       " 'sorry',\n",
       " 'thank you',\n",
       " 'welcome']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60cce95-0bba-4714-bbfa-8a84ef615115",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=os.listdir(data_dir)\n",
    "action_map={action:num for num,action in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d650fa-5171-4d84-9273-2754e124f0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afternoon': 0,\n",
       " 'blank': 1,\n",
       " 'evening': 2,\n",
       " 'fine': 3,\n",
       " 'hello': 4,\n",
       " 'how are you': 5,\n",
       " 'morning': 6,\n",
       " 'name': 7,\n",
       " 'sorry': 8,\n",
       " 'thank you': 9,\n",
       " 'welcome': 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cfe053-f90c-4ed8-bf1d-97c45688eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save_dir='../new_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dc3c5eb-53de-4b86-aed4-7bf518506d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in actions:\n",
    "    os.mkdir(os.path.join(to_save_dir,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8baa88b-6245-426c-b99f-370d6c3b92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [13:06<00:00, 71.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# x_data=[]\n",
    "# y_data=[]\n",
    "for action in tqdm.tqdm(actions):\n",
    "    index=action_map[action]\n",
    "    no_of_videos=len(os.listdir(os.path.join(data_dir,action)))\n",
    "    for video in range(no_of_videos):\n",
    "        window=[]\n",
    "        for frame in range(no_of_frames):\n",
    "            path=os.path.join(data_dir,action,str(video),f'{frame}.npy')\n",
    "            res=np.load(path)\n",
    "            array=res[:133].tolist()+res[1537:].tolist()\n",
    "            window.append(array)\n",
    "            \n",
    "        to_save_array=np.array(window)\n",
    "        path=os.path.join(to_save_dir,action,f'{video}.npy')\n",
    "        np.save(path,to_save_array)\n",
    "        \n",
    "        # x_data.append(window)\n",
    "        # y_data.append(index)\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14faca96-5660-40d8-9dde-f48bc9e097b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 258)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(os.path.join(to_save_dir,'afternoon','0.npy')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee872948-d961-48c6-99cc-ab9af6efc84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 2550, 2550)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_data),len(y_data),17*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e94298d9-6cde-45ab-9f96-40f9f5aa7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2643177e-d22a-441c-aabf-dce03d0db9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=keras.utils.to_categorical(np.array(y_data)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15cc8a9a-4325-438c-aace-2e95d7442ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2550, 17), (2550, 30, 1662))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aea6f2ba-7835-478d-bcdb-16cbbe9326e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c5dc156-cfcf-4c56-bafb-3e84d61cec12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2295, 30, 1662), (2295, 17))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e946b0b5-1902-42f7-8dde-a25e23880684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 30, 1662)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a93153ae-b126-4caf-ba0c-78a9d10445e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37f5adf0-4b08-4de2-a796-9ec84c20a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'my_best_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c91da59e-841d-47f4-bcf5-233208849f2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fe5d9cf-63be-426e-8db0-47f33a5a2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.GRU(64,activation='relu',return_sequences=True,input_shape=(30,1662)))\n",
    "model.add(keras.layers.GRU(128,activation='relu',return_sequences=True))\n",
    "model.add(keras.layers.GRU(32,activation='relu',return_sequences=False))\n",
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dense(64,activation='relu'))\n",
    "model.add(keras.layers.Dense(64,activation='relu'))\n",
    "model.add(keras.layers.Dense(17,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34d28ab6-b009-45d3-a488-7cb779f8af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.4357 - categorical_accuracy: 0.1743\n",
      "Epoch 1: val_loss improved from inf to 1.46032, saving model to my_best_model.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek chouhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 78s 290ms/step - loss: 2.4357 - categorical_accuracy: 0.1743 - val_loss: 1.4603 - val_categorical_accuracy: 0.3608\n",
      "Epoch 2/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1758 - categorical_accuracy: 0.5146\n",
      "Epoch 2: val_loss improved from 1.46032 to 0.91489, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 13s 182ms/step - loss: 1.1758 - categorical_accuracy: 0.5146 - val_loss: 0.9149 - val_categorical_accuracy: 0.5961\n",
      "Epoch 3/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8497 - categorical_accuracy: 0.6235\n",
      "Epoch 3: val_loss improved from 0.91489 to 0.64162, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.8497 - categorical_accuracy: 0.6235 - val_loss: 0.6416 - val_categorical_accuracy: 0.7137\n",
      "Epoch 4/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7499 - categorical_accuracy: 0.6662\n",
      "Epoch 4: val_loss improved from 0.64162 to 0.51747, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 138ms/step - loss: 0.7499 - categorical_accuracy: 0.6662 - val_loss: 0.5175 - val_categorical_accuracy: 0.7882\n",
      "Epoch 5/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6160 - categorical_accuracy: 0.7085\n",
      "Epoch 5: val_loss did not improve from 0.51747\n",
      "72/72 [==============================] - 9s 120ms/step - loss: 0.6160 - categorical_accuracy: 0.7085 - val_loss: 0.5712 - val_categorical_accuracy: 0.7373\n",
      "Epoch 6/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4929 - categorical_accuracy: 0.7599\n",
      "Epoch 6: val_loss did not improve from 0.51747\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.4929 - categorical_accuracy: 0.7599 - val_loss: 0.5827 - val_categorical_accuracy: 0.7608\n",
      "Epoch 7/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5291 - categorical_accuracy: 0.7473\n",
      "Epoch 7: val_loss improved from 0.51747 to 0.47086, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 132ms/step - loss: 0.5291 - categorical_accuracy: 0.7473 - val_loss: 0.4709 - val_categorical_accuracy: 0.7765\n",
      "Epoch 8/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4153 - categorical_accuracy: 0.7847\n",
      "Epoch 8: val_loss improved from 0.47086 to 0.43705, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 134ms/step - loss: 0.4153 - categorical_accuracy: 0.7847 - val_loss: 0.4370 - val_categorical_accuracy: 0.7765\n",
      "Epoch 9/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4706 - categorical_accuracy: 0.7765\n",
      "Epoch 9: val_loss improved from 0.43705 to 0.41810, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 14s 194ms/step - loss: 0.4706 - categorical_accuracy: 0.7765 - val_loss: 0.4181 - val_categorical_accuracy: 0.7961\n",
      "Epoch 10/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3799 - categorical_accuracy: 0.8227\n",
      "Epoch 10: val_loss did not improve from 0.41810\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.3799 - categorical_accuracy: 0.8227 - val_loss: 0.4370 - val_categorical_accuracy: 0.7804\n",
      "Epoch 11/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3954 - categorical_accuracy: 0.8061\n",
      "Epoch 11: val_loss improved from 0.41810 to 0.33510, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 135ms/step - loss: 0.3954 - categorical_accuracy: 0.8061 - val_loss: 0.3351 - val_categorical_accuracy: 0.8314\n",
      "Epoch 12/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3966 - categorical_accuracy: 0.8196\n",
      "Epoch 12: val_loss did not improve from 0.33510\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.3966 - categorical_accuracy: 0.8196 - val_loss: 0.3823 - val_categorical_accuracy: 0.8118\n",
      "Epoch 13/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3073 - categorical_accuracy: 0.8414\n",
      "Epoch 13: val_loss improved from 0.33510 to 0.29260, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.3073 - categorical_accuracy: 0.8414 - val_loss: 0.2926 - val_categorical_accuracy: 0.8431\n",
      "Epoch 14/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3198 - categorical_accuracy: 0.8414\n",
      "Epoch 14: val_loss did not improve from 0.29260\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.3198 - categorical_accuracy: 0.8414 - val_loss: 0.4044 - val_categorical_accuracy: 0.7804\n",
      "Epoch 15/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3328 - categorical_accuracy: 0.8340\n",
      "Epoch 15: val_loss improved from 0.29260 to 0.28096, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.3328 - categorical_accuracy: 0.8340 - val_loss: 0.2810 - val_categorical_accuracy: 0.8588\n",
      "Epoch 16/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2833 - categorical_accuracy: 0.8632\n",
      "Epoch 16: val_loss improved from 0.28096 to 0.25804, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 11s 150ms/step - loss: 0.2833 - categorical_accuracy: 0.8632 - val_loss: 0.2580 - val_categorical_accuracy: 0.8706\n",
      "Epoch 17/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2526 - categorical_accuracy: 0.8728\n",
      "Epoch 17: val_loss improved from 0.25804 to 0.25187, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 135ms/step - loss: 0.2526 - categorical_accuracy: 0.8728 - val_loss: 0.2519 - val_categorical_accuracy: 0.8667\n",
      "Epoch 18/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2278 - categorical_accuracy: 0.8937\n",
      "Epoch 18: val_loss improved from 0.25187 to 0.24642, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 146ms/step - loss: 0.2278 - categorical_accuracy: 0.8937 - val_loss: 0.2464 - val_categorical_accuracy: 0.8863\n",
      "Epoch 19/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.8889\n",
      "Epoch 19: val_loss did not improve from 0.24642\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.2321 - categorical_accuracy: 0.8889 - val_loss: 0.3774 - val_categorical_accuracy: 0.8235\n",
      "Epoch 20/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2529 - categorical_accuracy: 0.8797\n",
      "Epoch 20: val_loss did not improve from 0.24642\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.2529 - categorical_accuracy: 0.8797 - val_loss: 0.4824 - val_categorical_accuracy: 0.8039\n",
      "Epoch 21/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2070 - categorical_accuracy: 0.9011\n",
      "Epoch 21: val_loss did not improve from 0.24642\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.2070 - categorical_accuracy: 0.9011 - val_loss: 0.3832 - val_categorical_accuracy: 0.8588\n",
      "Epoch 22/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1995 - categorical_accuracy: 0.9033\n",
      "Epoch 22: val_loss did not improve from 0.24642\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.1995 - categorical_accuracy: 0.9033 - val_loss: 0.3584 - val_categorical_accuracy: 0.8667\n",
      "Epoch 23/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2074 - categorical_accuracy: 0.9033\n",
      "Epoch 23: val_loss did not improve from 0.24642\n",
      "72/72 [==============================] - 10s 132ms/step - loss: 0.2074 - categorical_accuracy: 0.9033 - val_loss: 0.2744 - val_categorical_accuracy: 0.8706\n",
      "Epoch 24/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1690 - categorical_accuracy: 0.9190\n",
      "Epoch 24: val_loss improved from 0.24642 to 0.20918, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 12s 163ms/step - loss: 0.1690 - categorical_accuracy: 0.9190 - val_loss: 0.2092 - val_categorical_accuracy: 0.8941\n",
      "Epoch 25/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.8837\n",
      "Epoch 25: val_loss did not improve from 0.20918\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.2516 - categorical_accuracy: 0.8837 - val_loss: 0.3113 - val_categorical_accuracy: 0.8549\n",
      "Epoch 26/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1889 - categorical_accuracy: 0.9046\n",
      "Epoch 26: val_loss did not improve from 0.20918\n",
      "72/72 [==============================] - 9s 121ms/step - loss: 0.1889 - categorical_accuracy: 0.9046 - val_loss: 0.3496 - val_categorical_accuracy: 0.8667\n",
      "Epoch 27/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2304 - categorical_accuracy: 0.8941\n",
      "Epoch 27: val_loss did not improve from 0.20918\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.2304 - categorical_accuracy: 0.8941 - val_loss: 0.4426 - val_categorical_accuracy: 0.8275\n",
      "Epoch 28/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1968 - categorical_accuracy: 0.9059\n",
      "Epoch 28: val_loss improved from 0.20918 to 0.19731, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 11s 147ms/step - loss: 0.1968 - categorical_accuracy: 0.9059 - val_loss: 0.1973 - val_categorical_accuracy: 0.9020\n",
      "Epoch 29/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1717 - categorical_accuracy: 0.9168\n",
      "Epoch 29: val_loss improved from 0.19731 to 0.19079, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.1717 - categorical_accuracy: 0.9168 - val_loss: 0.1908 - val_categorical_accuracy: 0.9020\n",
      "Epoch 30/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2244 - categorical_accuracy: 0.8828\n",
      "Epoch 30: val_loss did not improve from 0.19079\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.2244 - categorical_accuracy: 0.8828 - val_loss: 0.2512 - val_categorical_accuracy: 0.8902\n",
      "Epoch 31/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1463 - categorical_accuracy: 0.9229\n",
      "Epoch 31: val_loss improved from 0.19079 to 0.18494, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 134ms/step - loss: 0.1463 - categorical_accuracy: 0.9229 - val_loss: 0.1849 - val_categorical_accuracy: 0.9176\n",
      "Epoch 32/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2355 - categorical_accuracy: 0.8993\n",
      "Epoch 32: val_loss did not improve from 0.18494\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.2355 - categorical_accuracy: 0.8993 - val_loss: 0.2151 - val_categorical_accuracy: 0.8863\n",
      "Epoch 33/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1449 - categorical_accuracy: 0.9194\n",
      "Epoch 33: val_loss improved from 0.18494 to 0.18416, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 136ms/step - loss: 0.1449 - categorical_accuracy: 0.9194 - val_loss: 0.1842 - val_categorical_accuracy: 0.9098\n",
      "Epoch 34/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1342 - categorical_accuracy: 0.9281\n",
      "Epoch 34: val_loss did not improve from 0.18416\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.1342 - categorical_accuracy: 0.9281 - val_loss: 0.2043 - val_categorical_accuracy: 0.8863\n",
      "Epoch 35/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1644 - categorical_accuracy: 0.9155\n",
      "Epoch 35: val_loss improved from 0.18416 to 0.18013, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 132ms/step - loss: 0.1644 - categorical_accuracy: 0.9155 - val_loss: 0.1801 - val_categorical_accuracy: 0.9137\n",
      "Epoch 36/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1416 - categorical_accuracy: 0.9277\n",
      "Epoch 36: val_loss did not improve from 0.18013\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.1416 - categorical_accuracy: 0.9277 - val_loss: 0.2887 - val_categorical_accuracy: 0.8824\n",
      "Epoch 37/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1161 - categorical_accuracy: 0.9338\n",
      "Epoch 37: val_loss did not improve from 0.18013\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1161 - categorical_accuracy: 0.9338 - val_loss: 0.1832 - val_categorical_accuracy: 0.9059\n",
      "Epoch 38/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1392 - categorical_accuracy: 0.9251\n",
      "Epoch 38: val_loss did not improve from 0.18013\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1392 - categorical_accuracy: 0.9251 - val_loss: 0.1918 - val_categorical_accuracy: 0.9059\n",
      "Epoch 39/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1408 - categorical_accuracy: 0.9229\n",
      "Epoch 39: val_loss improved from 0.18013 to 0.15997, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.1408 - categorical_accuracy: 0.9229 - val_loss: 0.1600 - val_categorical_accuracy: 0.9020\n",
      "Epoch 40/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1437 - categorical_accuracy: 0.9229\n",
      "Epoch 40: val_loss did not improve from 0.15997\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1437 - categorical_accuracy: 0.9229 - val_loss: 0.4706 - val_categorical_accuracy: 0.8078\n",
      "Epoch 41/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1517 - categorical_accuracy: 0.9194\n",
      "Epoch 41: val_loss did not improve from 0.15997\n",
      "72/72 [==============================] - 9s 121ms/step - loss: 0.1517 - categorical_accuracy: 0.9194 - val_loss: 0.1747 - val_categorical_accuracy: 0.9137\n",
      "Epoch 42/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1136 - categorical_accuracy: 0.9246\n",
      "Epoch 42: val_loss improved from 0.15997 to 0.15289, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 136ms/step - loss: 0.1136 - categorical_accuracy: 0.9246 - val_loss: 0.1529 - val_categorical_accuracy: 0.9255\n",
      "Epoch 43/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1112 - categorical_accuracy: 0.9329\n",
      "Epoch 43: val_loss did not improve from 0.15289\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.1112 - categorical_accuracy: 0.9329 - val_loss: 0.2625 - val_categorical_accuracy: 0.8902\n",
      "Epoch 44/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1083 - categorical_accuracy: 0.9359\n",
      "Epoch 44: val_loss improved from 0.15289 to 0.13658, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.1083 - categorical_accuracy: 0.9359 - val_loss: 0.1366 - val_categorical_accuracy: 0.9137\n",
      "Epoch 45/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1057 - categorical_accuracy: 0.9346\n",
      "Epoch 45: val_loss did not improve from 0.13658\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.1057 - categorical_accuracy: 0.9346 - val_loss: 0.1667 - val_categorical_accuracy: 0.9098\n",
      "Epoch 46/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0967 - categorical_accuracy: 0.9394\n",
      "Epoch 46: val_loss did not improve from 0.13658\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0967 - categorical_accuracy: 0.9394 - val_loss: 0.1500 - val_categorical_accuracy: 0.9333\n",
      "Epoch 47/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0961 - categorical_accuracy: 0.9399\n",
      "Epoch 47: val_loss improved from 0.13658 to 0.13168, saving model to my_best_model.hdf5\n",
      "72/72 [==============================] - 9s 129ms/step - loss: 0.0961 - categorical_accuracy: 0.9399 - val_loss: 0.1317 - val_categorical_accuracy: 0.9373\n",
      "Epoch 48/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1985 - categorical_accuracy: 0.9181\n",
      "Epoch 48: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1985 - categorical_accuracy: 0.9181 - val_loss: 0.5565 - val_categorical_accuracy: 0.7686\n",
      "Epoch 49/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2091 - categorical_accuracy: 0.9015\n",
      "Epoch 49: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.2091 - categorical_accuracy: 0.9015 - val_loss: 0.1652 - val_categorical_accuracy: 0.9137\n",
      "Epoch 50/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1599 - categorical_accuracy: 0.9194\n",
      "Epoch 50: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1599 - categorical_accuracy: 0.9194 - val_loss: 0.3233 - val_categorical_accuracy: 0.8824\n",
      "Epoch 51/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1481 - categorical_accuracy: 0.9233\n",
      "Epoch 51: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1481 - categorical_accuracy: 0.9233 - val_loss: 0.2962 - val_categorical_accuracy: 0.8824\n",
      "Epoch 52/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.9255\n",
      "Epoch 52: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.1199 - categorical_accuracy: 0.9255 - val_loss: 0.2126 - val_categorical_accuracy: 0.9020\n",
      "Epoch 53/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9129\n",
      "Epoch 53: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.1704 - categorical_accuracy: 0.9129 - val_loss: 0.2250 - val_categorical_accuracy: 0.9098\n",
      "Epoch 54/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1083 - categorical_accuracy: 0.9329\n",
      "Epoch 54: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1083 - categorical_accuracy: 0.9329 - val_loss: 0.1874 - val_categorical_accuracy: 0.9020\n",
      "Epoch 55/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0992 - categorical_accuracy: 0.9364\n",
      "Epoch 55: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.0992 - categorical_accuracy: 0.9364 - val_loss: 0.1660 - val_categorical_accuracy: 0.9216\n",
      "Epoch 56/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1322 - categorical_accuracy: 0.9272\n",
      "Epoch 56: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1322 - categorical_accuracy: 0.9272 - val_loss: 0.3873 - val_categorical_accuracy: 0.8588\n",
      "Epoch 57/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3303 - categorical_accuracy: 0.8715\n",
      "Epoch 57: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.3303 - categorical_accuracy: 0.8715 - val_loss: 0.2821 - val_categorical_accuracy: 0.8824\n",
      "Epoch 58/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1389 - categorical_accuracy: 0.9220\n",
      "Epoch 58: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.1389 - categorical_accuracy: 0.9220 - val_loss: 0.1774 - val_categorical_accuracy: 0.9020\n",
      "Epoch 59/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1096 - categorical_accuracy: 0.9333\n",
      "Epoch 59: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.1096 - categorical_accuracy: 0.9333 - val_loss: 0.1507 - val_categorical_accuracy: 0.9137\n",
      "Epoch 60/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1267 - categorical_accuracy: 0.9251\n",
      "Epoch 60: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1267 - categorical_accuracy: 0.9251 - val_loss: 0.1764 - val_categorical_accuracy: 0.9176\n",
      "Epoch 61/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1260 - categorical_accuracy: 0.9264\n",
      "Epoch 61: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1260 - categorical_accuracy: 0.9264 - val_loss: 0.1649 - val_categorical_accuracy: 0.8980\n",
      "Epoch 62/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1004 - categorical_accuracy: 0.9368\n",
      "Epoch 62: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1004 - categorical_accuracy: 0.9368 - val_loss: 0.1810 - val_categorical_accuracy: 0.9216\n",
      "Epoch 63/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1031 - categorical_accuracy: 0.9312\n",
      "Epoch 63: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.1031 - categorical_accuracy: 0.9312 - val_loss: 0.1578 - val_categorical_accuracy: 0.9137\n",
      "Epoch 64/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1253 - categorical_accuracy: 0.9268\n",
      "Epoch 64: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.1253 - categorical_accuracy: 0.9268 - val_loss: 0.4630 - val_categorical_accuracy: 0.8510\n",
      "Epoch 65/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1128 - categorical_accuracy: 0.9277\n",
      "Epoch 65: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.1128 - categorical_accuracy: 0.9277 - val_loss: 0.1977 - val_categorical_accuracy: 0.9216\n",
      "Epoch 66/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2443 - categorical_accuracy: 0.8963\n",
      "Epoch 66: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.2443 - categorical_accuracy: 0.8963 - val_loss: 0.1705 - val_categorical_accuracy: 0.9059\n",
      "Epoch 67/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.9364\n",
      "Epoch 67: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1019 - categorical_accuracy: 0.9364 - val_loss: 0.1557 - val_categorical_accuracy: 0.9216\n",
      "Epoch 68/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0875 - categorical_accuracy: 0.9429\n",
      "Epoch 68: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0875 - categorical_accuracy: 0.9429 - val_loss: 0.1541 - val_categorical_accuracy: 0.9333\n",
      "Epoch 69/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.9277\n",
      "Epoch 69: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1191 - categorical_accuracy: 0.9277 - val_loss: 0.1924 - val_categorical_accuracy: 0.8980\n",
      "Epoch 70/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0961 - categorical_accuracy: 0.9351\n",
      "Epoch 70: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0961 - categorical_accuracy: 0.9351 - val_loss: 0.1621 - val_categorical_accuracy: 0.9216\n",
      "Epoch 71/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0883 - categorical_accuracy: 0.9403\n",
      "Epoch 71: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.0883 - categorical_accuracy: 0.9403 - val_loss: 0.1561 - val_categorical_accuracy: 0.9255\n",
      "Epoch 72/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0837 - categorical_accuracy: 0.9373\n",
      "Epoch 72: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 129ms/step - loss: 0.0837 - categorical_accuracy: 0.9373 - val_loss: 0.1711 - val_categorical_accuracy: 0.9098\n",
      "Epoch 73/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0890 - categorical_accuracy: 0.9303\n",
      "Epoch 73: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.0890 - categorical_accuracy: 0.9303 - val_loss: 0.1738 - val_categorical_accuracy: 0.9020\n",
      "Epoch 74/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2065 - categorical_accuracy: 0.9015\n",
      "Epoch 74: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 129ms/step - loss: 0.2065 - categorical_accuracy: 0.9015 - val_loss: 0.1946 - val_categorical_accuracy: 0.9137\n",
      "Epoch 75/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0957 - categorical_accuracy: 0.9416\n",
      "Epoch 75: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 129ms/step - loss: 0.0957 - categorical_accuracy: 0.9416 - val_loss: 0.1805 - val_categorical_accuracy: 0.9137\n",
      "Epoch 76/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0961 - categorical_accuracy: 0.9434\n",
      "Epoch 76: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.0961 - categorical_accuracy: 0.9434 - val_loss: 0.1974 - val_categorical_accuracy: 0.9216\n",
      "Epoch 77/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1187 - categorical_accuracy: 0.9259\n",
      "Epoch 77: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 127ms/step - loss: 0.1187 - categorical_accuracy: 0.9259 - val_loss: 0.2066 - val_categorical_accuracy: 0.9020\n",
      "Epoch 78/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1120 - categorical_accuracy: 0.9277\n",
      "Epoch 78: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.1120 - categorical_accuracy: 0.9277 - val_loss: 0.2903 - val_categorical_accuracy: 0.8941\n",
      "Epoch 79/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1023 - categorical_accuracy: 0.9351\n",
      "Epoch 79: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.1023 - categorical_accuracy: 0.9351 - val_loss: 0.2555 - val_categorical_accuracy: 0.8902\n",
      "Epoch 80/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1659 - categorical_accuracy: 0.9155\n",
      "Epoch 80: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 121ms/step - loss: 0.1659 - categorical_accuracy: 0.9155 - val_loss: 0.2817 - val_categorical_accuracy: 0.8980\n",
      "Epoch 81/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1058 - categorical_accuracy: 0.9294\n",
      "Epoch 81: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.1058 - categorical_accuracy: 0.9294 - val_loss: 0.1477 - val_categorical_accuracy: 0.9373\n",
      "Epoch 82/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1081 - categorical_accuracy: 0.9307\n",
      "Epoch 82: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1081 - categorical_accuracy: 0.9307 - val_loss: 0.2287 - val_categorical_accuracy: 0.8941\n",
      "Epoch 83/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1118 - categorical_accuracy: 0.9355\n",
      "Epoch 83: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.1118 - categorical_accuracy: 0.9355 - val_loss: 0.4333 - val_categorical_accuracy: 0.8471\n",
      "Epoch 84/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1255 - categorical_accuracy: 0.9203\n",
      "Epoch 84: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1255 - categorical_accuracy: 0.9203 - val_loss: 0.1721 - val_categorical_accuracy: 0.9216\n",
      "Epoch 85/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0995 - categorical_accuracy: 0.9342\n",
      "Epoch 85: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0995 - categorical_accuracy: 0.9342 - val_loss: 0.1663 - val_categorical_accuracy: 0.9137\n",
      "Epoch 86/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0844 - categorical_accuracy: 0.9386\n",
      "Epoch 86: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0844 - categorical_accuracy: 0.9386 - val_loss: 0.1630 - val_categorical_accuracy: 0.9176\n",
      "Epoch 87/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0835 - categorical_accuracy: 0.9386\n",
      "Epoch 87: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.0835 - categorical_accuracy: 0.9386 - val_loss: 0.1674 - val_categorical_accuracy: 0.9255\n",
      "Epoch 88/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0830 - categorical_accuracy: 0.9394\n",
      "Epoch 88: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0830 - categorical_accuracy: 0.9394 - val_loss: 0.1704 - val_categorical_accuracy: 0.9294\n",
      "Epoch 89/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0923 - categorical_accuracy: 0.9351\n",
      "Epoch 89: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0923 - categorical_accuracy: 0.9351 - val_loss: 0.1649 - val_categorical_accuracy: 0.9294\n",
      "Epoch 90/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0855 - categorical_accuracy: 0.9316\n",
      "Epoch 90: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0855 - categorical_accuracy: 0.9316 - val_loss: 0.1693 - val_categorical_accuracy: 0.9137\n",
      "Epoch 91/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9377\n",
      "Epoch 91: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.0822 - categorical_accuracy: 0.9377 - val_loss: 0.1821 - val_categorical_accuracy: 0.9216\n",
      "Epoch 92/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.9312\n",
      "Epoch 92: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.0839 - categorical_accuracy: 0.9312 - val_loss: 0.1723 - val_categorical_accuracy: 0.9294\n",
      "Epoch 93/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9420\n",
      "Epoch 93: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0823 - categorical_accuracy: 0.9420 - val_loss: 0.1777 - val_categorical_accuracy: 0.9176\n",
      "Epoch 94/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0820 - categorical_accuracy: 0.9407\n",
      "Epoch 94: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0820 - categorical_accuracy: 0.9407 - val_loss: 0.1779 - val_categorical_accuracy: 0.9176\n",
      "Epoch 95/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0831 - categorical_accuracy: 0.9407\n",
      "Epoch 95: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0831 - categorical_accuracy: 0.9407 - val_loss: 0.1762 - val_categorical_accuracy: 0.9176\n",
      "Epoch 96/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9394\n",
      "Epoch 96: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 131ms/step - loss: 0.0823 - categorical_accuracy: 0.9394 - val_loss: 0.1846 - val_categorical_accuracy: 0.9176\n",
      "Epoch 97/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9473\n",
      "Epoch 97: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 125ms/step - loss: 0.0823 - categorical_accuracy: 0.9473 - val_loss: 0.2070 - val_categorical_accuracy: 0.9255\n",
      "Epoch 98/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0975 - categorical_accuracy: 0.9333\n",
      "Epoch 98: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0975 - categorical_accuracy: 0.9333 - val_loss: 0.2108 - val_categorical_accuracy: 0.9216\n",
      "Epoch 99/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0899 - categorical_accuracy: 0.9390\n",
      "Epoch 99: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.0899 - categorical_accuracy: 0.9390 - val_loss: 0.2898 - val_categorical_accuracy: 0.9137\n",
      "Epoch 100/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1998 - categorical_accuracy: 0.9050\n",
      "Epoch 100: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.1998 - categorical_accuracy: 0.9050 - val_loss: 0.2171 - val_categorical_accuracy: 0.9137\n",
      "Epoch 101/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1768 - categorical_accuracy: 0.9159\n",
      "Epoch 101: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 120ms/step - loss: 0.1768 - categorical_accuracy: 0.9159 - val_loss: 0.4524 - val_categorical_accuracy: 0.8353\n",
      "Epoch 102/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2025 - categorical_accuracy: 0.9041\n",
      "Epoch 102: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 113ms/step - loss: 0.2025 - categorical_accuracy: 0.9041 - val_loss: 0.1859 - val_categorical_accuracy: 0.8980\n",
      "Epoch 103/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1002 - categorical_accuracy: 0.9338\n",
      "Epoch 103: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 114ms/step - loss: 0.1002 - categorical_accuracy: 0.9338 - val_loss: 0.2032 - val_categorical_accuracy: 0.9216\n",
      "Epoch 104/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0870 - categorical_accuracy: 0.9394\n",
      "Epoch 104: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 0.0870 - categorical_accuracy: 0.9394 - val_loss: 0.1842 - val_categorical_accuracy: 0.9294\n",
      "Epoch 105/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0841 - categorical_accuracy: 0.9425\n",
      "Epoch 105: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 0.0841 - categorical_accuracy: 0.9425 - val_loss: 0.1969 - val_categorical_accuracy: 0.9216\n",
      "Epoch 106/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0830 - categorical_accuracy: 0.9386\n",
      "Epoch 106: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 0.0830 - categorical_accuracy: 0.9386 - val_loss: 0.1930 - val_categorical_accuracy: 0.9294\n",
      "Epoch 107/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0854 - categorical_accuracy: 0.9412\n",
      "Epoch 107: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 0.0854 - categorical_accuracy: 0.9412 - val_loss: 0.1811 - val_categorical_accuracy: 0.9216\n",
      "Epoch 108/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0825 - categorical_accuracy: 0.9386\n",
      "Epoch 108: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 115ms/step - loss: 0.0825 - categorical_accuracy: 0.9386 - val_loss: 0.1932 - val_categorical_accuracy: 0.9059\n",
      "Epoch 109/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.9390\n",
      "Epoch 109: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0839 - categorical_accuracy: 0.9390 - val_loss: 0.1957 - val_categorical_accuracy: 0.9216\n",
      "Epoch 110/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0825 - categorical_accuracy: 0.9394\n",
      "Epoch 110: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.0825 - categorical_accuracy: 0.9394 - val_loss: 0.1845 - val_categorical_accuracy: 0.9176\n",
      "Epoch 111/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0821 - categorical_accuracy: 0.9425\n",
      "Epoch 111: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 112ms/step - loss: 0.0821 - categorical_accuracy: 0.9425 - val_loss: 0.1999 - val_categorical_accuracy: 0.9176\n",
      "Epoch 112/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9377\n",
      "Epoch 112: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0819 - categorical_accuracy: 0.9377 - val_loss: 0.2039 - val_categorical_accuracy: 0.8980\n",
      "Epoch 113/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9394\n",
      "Epoch 113: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0822 - categorical_accuracy: 0.9394 - val_loss: 0.2069 - val_categorical_accuracy: 0.9294\n",
      "Epoch 114/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0821 - categorical_accuracy: 0.9364\n",
      "Epoch 114: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.0821 - categorical_accuracy: 0.9364 - val_loss: 0.2077 - val_categorical_accuracy: 0.9176\n",
      "Epoch 115/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9460\n",
      "Epoch 115: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.0814 - categorical_accuracy: 0.9460 - val_loss: 0.2122 - val_categorical_accuracy: 0.9216\n",
      "Epoch 116/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0832 - categorical_accuracy: 0.9355\n",
      "Epoch 116: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0832 - categorical_accuracy: 0.9355 - val_loss: 0.1980 - val_categorical_accuracy: 0.9255\n",
      "Epoch 117/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0820 - categorical_accuracy: 0.9351\n",
      "Epoch 117: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0820 - categorical_accuracy: 0.9351 - val_loss: 0.2074 - val_categorical_accuracy: 0.9255\n",
      "Epoch 118/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9351\n",
      "Epoch 118: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.0819 - categorical_accuracy: 0.9351 - val_loss: 0.2121 - val_categorical_accuracy: 0.9137\n",
      "Epoch 119/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9368\n",
      "Epoch 119: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 115ms/step - loss: 0.0819 - categorical_accuracy: 0.9368 - val_loss: 0.2058 - val_categorical_accuracy: 0.9098\n",
      "Epoch 120/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9355\n",
      "Epoch 120: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.0816 - categorical_accuracy: 0.9355 - val_loss: 0.2084 - val_categorical_accuracy: 0.9294\n",
      "Epoch 121/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9081\n",
      "Epoch 121: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.1882 - categorical_accuracy: 0.9081 - val_loss: 0.2624 - val_categorical_accuracy: 0.8902\n",
      "Epoch 122/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2476 - categorical_accuracy: 0.8906\n",
      "Epoch 122: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.2476 - categorical_accuracy: 0.8906 - val_loss: 0.1987 - val_categorical_accuracy: 0.9098\n",
      "Epoch 123/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1255 - categorical_accuracy: 0.9312\n",
      "Epoch 123: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 111ms/step - loss: 0.1255 - categorical_accuracy: 0.9312 - val_loss: 0.2235 - val_categorical_accuracy: 0.9098\n",
      "Epoch 124/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1263 - categorical_accuracy: 0.9338\n",
      "Epoch 124: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 110ms/step - loss: 0.1263 - categorical_accuracy: 0.9338 - val_loss: 0.2404 - val_categorical_accuracy: 0.9020\n",
      "Epoch 125/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.9312\n",
      "Epoch 125: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.1044 - categorical_accuracy: 0.9312 - val_loss: 0.2675 - val_categorical_accuracy: 0.9020\n",
      "Epoch 126/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.9303\n",
      "Epoch 126: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 138ms/step - loss: 0.1199 - categorical_accuracy: 0.9303 - val_loss: 0.1716 - val_categorical_accuracy: 0.9294\n",
      "Epoch 127/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0988 - categorical_accuracy: 0.9259\n",
      "Epoch 127: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 170ms/step - loss: 0.0988 - categorical_accuracy: 0.9259 - val_loss: 0.1910 - val_categorical_accuracy: 0.9216\n",
      "Epoch 128/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1308 - categorical_accuracy: 0.9246\n",
      "Epoch 128: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 165ms/step - loss: 0.1308 - categorical_accuracy: 0.9246 - val_loss: 0.1657 - val_categorical_accuracy: 0.9176\n",
      "Epoch 129/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0846 - categorical_accuracy: 0.9377\n",
      "Epoch 129: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 161ms/step - loss: 0.0846 - categorical_accuracy: 0.9377 - val_loss: 0.1684 - val_categorical_accuracy: 0.9098\n",
      "Epoch 130/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0827 - categorical_accuracy: 0.9429\n",
      "Epoch 130: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 154ms/step - loss: 0.0827 - categorical_accuracy: 0.9429 - val_loss: 0.1784 - val_categorical_accuracy: 0.9176\n",
      "Epoch 131/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9425\n",
      "Epoch 131: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 146ms/step - loss: 0.0822 - categorical_accuracy: 0.9425 - val_loss: 0.1737 - val_categorical_accuracy: 0.9294\n",
      "Epoch 132/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0818 - categorical_accuracy: 0.9407\n",
      "Epoch 132: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 129ms/step - loss: 0.0818 - categorical_accuracy: 0.9407 - val_loss: 0.1820 - val_categorical_accuracy: 0.9137\n",
      "Epoch 133/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0820 - categorical_accuracy: 0.9416\n",
      "Epoch 133: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.0820 - categorical_accuracy: 0.9416 - val_loss: 0.1824 - val_categorical_accuracy: 0.9098\n",
      "Epoch 134/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0828 - categorical_accuracy: 0.9390\n",
      "Epoch 134: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 141ms/step - loss: 0.0828 - categorical_accuracy: 0.9390 - val_loss: 0.1806 - val_categorical_accuracy: 0.9255\n",
      "Epoch 135/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0817 - categorical_accuracy: 0.9420\n",
      "Epoch 135: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.0817 - categorical_accuracy: 0.9420 - val_loss: 0.1850 - val_categorical_accuracy: 0.9255\n",
      "Epoch 136/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0827 - categorical_accuracy: 0.9338\n",
      "Epoch 136: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.0827 - categorical_accuracy: 0.9338 - val_loss: 0.1829 - val_categorical_accuracy: 0.9255\n",
      "Epoch 137/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0818 - categorical_accuracy: 0.9346\n",
      "Epoch 137: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 133ms/step - loss: 0.0818 - categorical_accuracy: 0.9346 - val_loss: 0.1851 - val_categorical_accuracy: 0.9176\n",
      "Epoch 138/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9473\n",
      "Epoch 138: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 138ms/step - loss: 0.0823 - categorical_accuracy: 0.9473 - val_loss: 0.1792 - val_categorical_accuracy: 0.9294\n",
      "Epoch 139/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0825 - categorical_accuracy: 0.9386\n",
      "Epoch 139: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 133ms/step - loss: 0.0825 - categorical_accuracy: 0.9386 - val_loss: 0.1866 - val_categorical_accuracy: 0.9098\n",
      "Epoch 140/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9420\n",
      "Epoch 140: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 131ms/step - loss: 0.0815 - categorical_accuracy: 0.9420 - val_loss: 0.1927 - val_categorical_accuracy: 0.9059\n",
      "Epoch 141/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0836 - categorical_accuracy: 0.9364\n",
      "Epoch 141: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 127ms/step - loss: 0.0836 - categorical_accuracy: 0.9364 - val_loss: 0.1831 - val_categorical_accuracy: 0.9294\n",
      "Epoch 142/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9434\n",
      "Epoch 142: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 127ms/step - loss: 0.0815 - categorical_accuracy: 0.9434 - val_loss: 0.1925 - val_categorical_accuracy: 0.9176\n",
      "Epoch 143/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0813 - categorical_accuracy: 0.9468\n",
      "Epoch 143: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.0813 - categorical_accuracy: 0.9468 - val_loss: 0.1912 - val_categorical_accuracy: 0.9294\n",
      "Epoch 144/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9416\n",
      "Epoch 144: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 128ms/step - loss: 0.0815 - categorical_accuracy: 0.9416 - val_loss: 0.2007 - val_categorical_accuracy: 0.9176\n",
      "Epoch 145/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0833 - categorical_accuracy: 0.9394\n",
      "Epoch 145: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 137ms/step - loss: 0.0833 - categorical_accuracy: 0.9394 - val_loss: 0.1921 - val_categorical_accuracy: 0.9176\n",
      "Epoch 146/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9429\n",
      "Epoch 146: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.0819 - categorical_accuracy: 0.9429 - val_loss: 0.1900 - val_categorical_accuracy: 0.9294\n",
      "Epoch 147/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9438\n",
      "Epoch 147: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.0814 - categorical_accuracy: 0.9438 - val_loss: 0.2008 - val_categorical_accuracy: 0.9176\n",
      "Epoch 148/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9381\n",
      "Epoch 148: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 160ms/step - loss: 0.0816 - categorical_accuracy: 0.9381 - val_loss: 0.2011 - val_categorical_accuracy: 0.9255\n",
      "Epoch 149/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9386\n",
      "Epoch 149: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 154ms/step - loss: 0.0816 - categorical_accuracy: 0.9386 - val_loss: 0.2004 - val_categorical_accuracy: 0.9216\n",
      "Epoch 150/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9403\n",
      "Epoch 150: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 170ms/step - loss: 0.0822 - categorical_accuracy: 0.9403 - val_loss: 0.2001 - val_categorical_accuracy: 0.9176\n",
      "Epoch 151/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0828 - categorical_accuracy: 0.9342\n",
      "Epoch 151: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 163ms/step - loss: 0.0828 - categorical_accuracy: 0.9342 - val_loss: 0.1943 - val_categorical_accuracy: 0.9020\n",
      "Epoch 152/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9455\n",
      "Epoch 152: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 13s 185ms/step - loss: 0.0815 - categorical_accuracy: 0.9455 - val_loss: 0.1977 - val_categorical_accuracy: 0.9294\n",
      "Epoch 153/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0821 - categorical_accuracy: 0.9377\n",
      "Epoch 153: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 16s 220ms/step - loss: 0.0821 - categorical_accuracy: 0.9377 - val_loss: 0.1919 - val_categorical_accuracy: 0.9294\n",
      "Epoch 154/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9355\n",
      "Epoch 154: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 13s 174ms/step - loss: 0.0819 - categorical_accuracy: 0.9355 - val_loss: 0.2054 - val_categorical_accuracy: 0.9137\n",
      "Epoch 155/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9420\n",
      "Epoch 155: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 120ms/step - loss: 0.0815 - categorical_accuracy: 0.9420 - val_loss: 0.1996 - val_categorical_accuracy: 0.9294\n",
      "Epoch 156/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9407\n",
      "Epoch 156: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 134ms/step - loss: 0.0816 - categorical_accuracy: 0.9407 - val_loss: 0.2036 - val_categorical_accuracy: 0.9294\n",
      "Epoch 157/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0820 - categorical_accuracy: 0.9355\n",
      "Epoch 157: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 155ms/step - loss: 0.0820 - categorical_accuracy: 0.9355 - val_loss: 0.2082 - val_categorical_accuracy: 0.9294\n",
      "Epoch 158/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0826 - categorical_accuracy: 0.9412\n",
      "Epoch 158: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 118ms/step - loss: 0.0826 - categorical_accuracy: 0.9412 - val_loss: 0.2015 - val_categorical_accuracy: 0.9137\n",
      "Epoch 159/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0818 - categorical_accuracy: 0.9425\n",
      "Epoch 159: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.0818 - categorical_accuracy: 0.9425 - val_loss: 0.2090 - val_categorical_accuracy: 0.9255\n",
      "Epoch 160/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9333\n",
      "Epoch 160: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 138ms/step - loss: 0.0816 - categorical_accuracy: 0.9333 - val_loss: 0.2108 - val_categorical_accuracy: 0.9294\n",
      "Epoch 161/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0813 - categorical_accuracy: 0.9394\n",
      "Epoch 161: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 130ms/step - loss: 0.0813 - categorical_accuracy: 0.9394 - val_loss: 0.2193 - val_categorical_accuracy: 0.9137\n",
      "Epoch 162/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9416\n",
      "Epoch 162: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.0814 - categorical_accuracy: 0.9416 - val_loss: 0.2167 - val_categorical_accuracy: 0.9137\n",
      "Epoch 163/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9420\n",
      "Epoch 163: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 118ms/step - loss: 0.0814 - categorical_accuracy: 0.9420 - val_loss: 0.2201 - val_categorical_accuracy: 0.9216\n",
      "Epoch 164/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0817 - categorical_accuracy: 0.9420\n",
      "Epoch 164: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 122ms/step - loss: 0.0817 - categorical_accuracy: 0.9420 - val_loss: 0.2112 - val_categorical_accuracy: 0.9294\n",
      "Epoch 165/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9416\n",
      "Epoch 165: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.0815 - categorical_accuracy: 0.9416 - val_loss: 0.2150 - val_categorical_accuracy: 0.9294\n",
      "Epoch 166/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9381\n",
      "Epoch 166: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 119ms/step - loss: 0.0816 - categorical_accuracy: 0.9381 - val_loss: 0.2164 - val_categorical_accuracy: 0.9137\n",
      "Epoch 167/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9377\n",
      "Epoch 167: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 153ms/step - loss: 0.0819 - categorical_accuracy: 0.9377 - val_loss: 0.2168 - val_categorical_accuracy: 0.9137\n",
      "Epoch 168/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0812 - categorical_accuracy: 0.9425\n",
      "Epoch 168: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 158ms/step - loss: 0.0812 - categorical_accuracy: 0.9425 - val_loss: 0.2177 - val_categorical_accuracy: 0.9255\n",
      "Epoch 169/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0816 - categorical_accuracy: 0.9416\n",
      "Epoch 169: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 124ms/step - loss: 0.0816 - categorical_accuracy: 0.9416 - val_loss: 0.2220 - val_categorical_accuracy: 0.9137\n",
      "Epoch 170/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0813 - categorical_accuracy: 0.9377\n",
      "Epoch 170: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.0813 - categorical_accuracy: 0.9377 - val_loss: 0.2273 - val_categorical_accuracy: 0.9294\n",
      "Epoch 171/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3461 - categorical_accuracy: 0.8780\n",
      "Epoch 171: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 120ms/step - loss: 0.3461 - categorical_accuracy: 0.8780 - val_loss: 0.5277 - val_categorical_accuracy: 0.8549\n",
      "Epoch 172/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2528 - categorical_accuracy: 0.8911\n",
      "Epoch 172: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 123ms/step - loss: 0.2528 - categorical_accuracy: 0.8911 - val_loss: 0.2832 - val_categorical_accuracy: 0.8667\n",
      "Epoch 173/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9342\n",
      "Epoch 173: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.1032 - categorical_accuracy: 0.9342 - val_loss: 0.1779 - val_categorical_accuracy: 0.9294\n",
      "Epoch 174/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0996 - categorical_accuracy: 0.9294\n",
      "Epoch 174: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 141ms/step - loss: 0.0996 - categorical_accuracy: 0.9294 - val_loss: 0.2094 - val_categorical_accuracy: 0.8941\n",
      "Epoch 175/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1029 - categorical_accuracy: 0.9351\n",
      "Epoch 175: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.1029 - categorical_accuracy: 0.9351 - val_loss: 0.2025 - val_categorical_accuracy: 0.9176\n",
      "Epoch 176/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1087 - categorical_accuracy: 0.9307\n",
      "Epoch 176: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 8s 117ms/step - loss: 0.1087 - categorical_accuracy: 0.9307 - val_loss: 0.2027 - val_categorical_accuracy: 0.9020\n",
      "Epoch 177/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1094 - categorical_accuracy: 0.9303\n",
      "Epoch 177: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 9s 126ms/step - loss: 0.1094 - categorical_accuracy: 0.9303 - val_loss: 0.1633 - val_categorical_accuracy: 0.9176\n",
      "Epoch 178/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1032 - categorical_accuracy: 0.9338\n",
      "Epoch 178: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 168ms/step - loss: 0.1032 - categorical_accuracy: 0.9338 - val_loss: 0.1861 - val_categorical_accuracy: 0.9176\n",
      "Epoch 179/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0873 - categorical_accuracy: 0.9377\n",
      "Epoch 179: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 165ms/step - loss: 0.0873 - categorical_accuracy: 0.9377 - val_loss: 0.1684 - val_categorical_accuracy: 0.9255\n",
      "Epoch 180/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0837 - categorical_accuracy: 0.9333\n",
      "Epoch 180: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.0837 - categorical_accuracy: 0.9333 - val_loss: 0.1950 - val_categorical_accuracy: 0.9216\n",
      "Epoch 181/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1828 - categorical_accuracy: 0.9176\n",
      "Epoch 181: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 136ms/step - loss: 0.1828 - categorical_accuracy: 0.9176 - val_loss: 0.1957 - val_categorical_accuracy: 0.9098\n",
      "Epoch 182/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0999 - categorical_accuracy: 0.9359\n",
      "Epoch 182: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 156ms/step - loss: 0.0999 - categorical_accuracy: 0.9359 - val_loss: 0.5133 - val_categorical_accuracy: 0.8471\n",
      "Epoch 183/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1997 - categorical_accuracy: 0.9002\n",
      "Epoch 183: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 154ms/step - loss: 0.1997 - categorical_accuracy: 0.9002 - val_loss: 0.1755 - val_categorical_accuracy: 0.9098\n",
      "Epoch 184/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9298\n",
      "Epoch 184: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 162ms/step - loss: 0.1063 - categorical_accuracy: 0.9298 - val_loss: 0.1489 - val_categorical_accuracy: 0.9137\n",
      "Epoch 185/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0875 - categorical_accuracy: 0.9399\n",
      "Epoch 185: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 161ms/step - loss: 0.0875 - categorical_accuracy: 0.9399 - val_loss: 0.1874 - val_categorical_accuracy: 0.9137\n",
      "Epoch 186/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0974 - categorical_accuracy: 0.9386\n",
      "Epoch 186: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 12s 166ms/step - loss: 0.0974 - categorical_accuracy: 0.9386 - val_loss: 0.1734 - val_categorical_accuracy: 0.9176\n",
      "Epoch 187/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0833 - categorical_accuracy: 0.9407\n",
      "Epoch 187: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 154ms/step - loss: 0.0833 - categorical_accuracy: 0.9407 - val_loss: 0.1632 - val_categorical_accuracy: 0.9176\n",
      "Epoch 188/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0830 - categorical_accuracy: 0.9368\n",
      "Epoch 188: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 157ms/step - loss: 0.0830 - categorical_accuracy: 0.9368 - val_loss: 0.1786 - val_categorical_accuracy: 0.9176\n",
      "Epoch 189/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0818 - categorical_accuracy: 0.9399\n",
      "Epoch 189: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 148ms/step - loss: 0.0818 - categorical_accuracy: 0.9399 - val_loss: 0.1709 - val_categorical_accuracy: 0.9176\n",
      "Epoch 190/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0820 - categorical_accuracy: 0.9364\n",
      "Epoch 190: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.0820 - categorical_accuracy: 0.9364 - val_loss: 0.1691 - val_categorical_accuracy: 0.9216\n",
      "Epoch 191/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9455\n",
      "Epoch 191: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 144ms/step - loss: 0.0815 - categorical_accuracy: 0.9455 - val_loss: 0.1857 - val_categorical_accuracy: 0.9176\n",
      "Epoch 192/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0817 - categorical_accuracy: 0.9412\n",
      "Epoch 192: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 140ms/step - loss: 0.0817 - categorical_accuracy: 0.9412 - val_loss: 0.1776 - val_categorical_accuracy: 0.9216\n",
      "Epoch 193/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0818 - categorical_accuracy: 0.9373\n",
      "Epoch 193: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.0818 - categorical_accuracy: 0.9373 - val_loss: 0.1791 - val_categorical_accuracy: 0.9176\n",
      "Epoch 194/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0839 - categorical_accuracy: 0.9399\n",
      "Epoch 194: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 135ms/step - loss: 0.0839 - categorical_accuracy: 0.9399 - val_loss: 0.3769 - val_categorical_accuracy: 0.8824\n",
      "Epoch 195/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1306 - categorical_accuracy: 0.9290\n",
      "Epoch 195: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 143ms/step - loss: 0.1306 - categorical_accuracy: 0.9290 - val_loss: 0.1503 - val_categorical_accuracy: 0.9098\n",
      "Epoch 196/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1510 - categorical_accuracy: 0.9159\n",
      "Epoch 196: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 140ms/step - loss: 0.1510 - categorical_accuracy: 0.9159 - val_loss: 0.1586 - val_categorical_accuracy: 0.9216\n",
      "Epoch 197/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9394\n",
      "Epoch 197: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 135ms/step - loss: 0.0908 - categorical_accuracy: 0.9394 - val_loss: 0.1536 - val_categorical_accuracy: 0.9216\n",
      "Epoch 198/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0838 - categorical_accuracy: 0.9364\n",
      "Epoch 198: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 142ms/step - loss: 0.0838 - categorical_accuracy: 0.9364 - val_loss: 0.1559 - val_categorical_accuracy: 0.9216\n",
      "Epoch 199/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0822 - categorical_accuracy: 0.9412\n",
      "Epoch 199: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 10s 139ms/step - loss: 0.0822 - categorical_accuracy: 0.9412 - val_loss: 0.1665 - val_categorical_accuracy: 0.9216\n",
      "Epoch 200/200\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.0823 - categorical_accuracy: 0.9381\n",
      "Epoch 200: val_loss did not improve from 0.13168\n",
      "72/72 [==============================] - 11s 156ms/step - loss: 0.0823 - categorical_accuracy: 0.9381 - val_loss: 0.1741 - val_categorical_accuracy: 0.9176\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=200,validation_data=(x_test,y_test),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e4444c-ab2c-474c-9787-d6df3cfde0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "85/85 [==============================] - 15s 121ms/step - loss: 0.1260 - categorical_accuracy: 0.9311 - val_loss: 0.2659 - val_categorical_accuracy: 0.8967\n",
      "Epoch 2/30\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.1424 - categorical_accuracy: 0.9274 - val_loss: 0.4426 - val_categorical_accuracy: 0.8633\n",
      "Epoch 3/30\n",
      "85/85 [==============================] - 10s 117ms/step - loss: 0.1325 - categorical_accuracy: 0.9304 - val_loss: 0.3474 - val_categorical_accuracy: 0.8633\n",
      "Epoch 4/30\n",
      "85/85 [==============================] - 10s 117ms/step - loss: 0.1414 - categorical_accuracy: 0.9267 - val_loss: 0.2421 - val_categorical_accuracy: 0.9167\n",
      "Epoch 5/30\n",
      "85/85 [==============================] - 10s 117ms/step - loss: 0.1327 - categorical_accuracy: 0.9330 - val_loss: 0.2777 - val_categorical_accuracy: 0.8833\n",
      "Epoch 6/30\n",
      "85/85 [==============================] - 10s 117ms/step - loss: 0.1460 - categorical_accuracy: 0.9241 - val_loss: 0.2294 - val_categorical_accuracy: 0.9167\n",
      "Epoch 7/30\n",
      "85/85 [==============================] - 9s 110ms/step - loss: 0.1168 - categorical_accuracy: 0.9374 - val_loss: 0.2511 - val_categorical_accuracy: 0.9133\n",
      "Epoch 8/30\n",
      "85/85 [==============================] - 9s 109ms/step - loss: 0.1231 - categorical_accuracy: 0.9330 - val_loss: 0.2834 - val_categorical_accuracy: 0.9200\n",
      "Epoch 9/30\n",
      "85/85 [==============================] - 9s 108ms/step - loss: 0.1452 - categorical_accuracy: 0.9259 - val_loss: 0.2605 - val_categorical_accuracy: 0.9100\n",
      "Epoch 10/30\n",
      "85/85 [==============================] - 10s 116ms/step - loss: 0.1510 - categorical_accuracy: 0.9233 - val_loss: 0.3308 - val_categorical_accuracy: 0.8833\n",
      "Epoch 11/30\n",
      "85/85 [==============================] - 10s 115ms/step - loss: 0.1214 - categorical_accuracy: 0.9322 - val_loss: 0.2966 - val_categorical_accuracy: 0.9100\n",
      "Epoch 12/30\n",
      "85/85 [==============================] - 10s 122ms/step - loss: 0.1211 - categorical_accuracy: 0.9385 - val_loss: 0.2282 - val_categorical_accuracy: 0.9200\n",
      "Epoch 13/30\n",
      "85/85 [==============================] - 10s 113ms/step - loss: 0.1094 - categorical_accuracy: 0.9393 - val_loss: 0.3108 - val_categorical_accuracy: 0.9033\n",
      "Epoch 14/30\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.1507 - categorical_accuracy: 0.9256 - val_loss: 0.2258 - val_categorical_accuracy: 0.9233\n",
      "Epoch 15/30\n",
      "85/85 [==============================] - 9s 112ms/step - loss: 0.1019 - categorical_accuracy: 0.9441 - val_loss: 0.2515 - val_categorical_accuracy: 0.9000\n",
      "Epoch 16/30\n",
      "85/85 [==============================] - 10s 116ms/step - loss: 0.1377 - categorical_accuracy: 0.9344 - val_loss: 0.2699 - val_categorical_accuracy: 0.9000\n",
      "Epoch 17/30\n",
      "62/85 [====================>.........] - ETA: 2s - loss: 0.1818 - categorical_accuracy: 0.9148"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history2\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history2=model.fit(x_train,y_train,epochs=30,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9a1cf27-4b8b-4d74-ae97-f1d1b9701575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 30ms/step - loss: 0.0404 - categorical_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04038967937231064, 0.9833333492279053]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0145e6a9-eb2b-4471-9410-afa774d8cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 41ms/step - loss: 0.1741 - categorical_accuracy: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.174140065908432, 0.9176470637321472]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a4e220-c213-404c-b232-be9a60f425a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c41193a-ed3b-444e-8bf1-b332a5886171",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_2_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory_2_v2\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_2_v2\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Stats\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_2_v2' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_2_v2.history['loss'])\n",
    "plt.plot(history_2_v2.history['categorical_accuracy'])\n",
    "plt.title('Training Stats')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['training_loss','traning categorical_accuracy'])\n",
    "plt.savefig('training_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69529931-4965-4b25-9ae8-7cb705bd3996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_2_v2.history['val_loss'])\n",
    "plt.plot(history_2_v2.history['val_categorical_accuracy'])\n",
    "plt.title('Training Stats')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['testing_loss','testing categorical_accuracy'])\n",
    "plt.savefig('testing_stats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "054926b1-ab1f-421a-8c43-e69115ff7100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek chouhan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "gru_model2_v2.save('gru_isl_model_extra_v2.keras')\n",
    "gru_model2_v2.save('gru_isl_model_extra_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80dd9d23-a984-4465-b1a1-c212c5d7a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ea7d139-b130-431e-9919-e66c6d84bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(actions,open('new_classes.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68f67d1d-2250-42d8-a429-5949a74579db",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[np.argmax(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83d686f6-e24f-4365-8022-11f3a3fd3a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd18b30f-b11b-4d2e-b2b0-78e4b0405a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "y_p=gru_model2_v2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "016a2830-0bfc-4f98-aaae-9496d45e5575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0991516e-11, 1.5915861e-06, 1.7602229e-05, 2.9272464e-04,\n",
       "        3.4122996e-02, 9.6556503e-01],\n",
       "       [2.1456553e-10, 9.6570851e-08, 2.1201344e-04, 8.6935339e-03,\n",
       "        3.4385999e-03, 9.8765570e-01],\n",
       "       [9.9828440e-01, 1.3990568e-03, 1.9528099e-07, 2.6365076e-04,\n",
       "        9.8078626e-06, 4.2761432e-05],\n",
       "       [1.5491990e-10, 1.1384355e-07, 9.9908757e-01, 6.9884126e-10,\n",
       "        8.6657028e-04, 4.5797864e-05],\n",
       "       [8.0207320e-15, 1.3361032e-11, 2.1496926e-06, 3.4936625e-07,\n",
       "        2.9814078e-03, 9.9701607e-01],\n",
       "       [3.3969862e-09, 1.8448958e-05, 1.1921901e-03, 2.7535358e-05,\n",
       "        8.7938541e-01, 1.1937642e-01],\n",
       "       [2.3373993e-15, 7.6752504e-13, 1.5847012e-07, 5.9118061e-06,\n",
       "        2.2797358e-05, 9.9997115e-01],\n",
       "       [1.0250419e-08, 4.1355665e-06, 9.7584730e-01, 1.6533741e-08,\n",
       "        2.3974326e-02, 1.7417989e-04],\n",
       "       [6.2335333e-05, 9.9906415e-01, 3.0153806e-05, 4.6705865e-04,\n",
       "        2.9726129e-04, 7.8963087e-05],\n",
       "       [3.9946135e-10, 1.2318050e-07, 9.9950552e-01, 9.8987085e-10,\n",
       "        4.2724636e-04, 6.7092675e-05],\n",
       "       [1.0808837e-11, 4.0923524e-07, 3.3986523e-06, 8.5787702e-01,\n",
       "        2.2492296e-04, 1.4189430e-01],\n",
       "       [6.7990013e-06, 9.9802041e-01, 1.5712762e-04, 6.2322582e-04,\n",
       "        1.0174381e-03, 1.7498306e-04],\n",
       "       [5.9802024e-10, 4.7433230e-07, 9.9707055e-01, 9.7126063e-10,\n",
       "        2.8838303e-03, 4.5164910e-05],\n",
       "       [1.6669400e-09, 6.4533407e-07, 9.9630690e-01, 2.1864341e-09,\n",
       "        3.6034461e-03, 8.9059846e-05],\n",
       "       [9.9729663e-01, 2.2719989e-03, 4.0315982e-07, 3.4965691e-04,\n",
       "        1.6780850e-05, 6.4575463e-05],\n",
       "       [7.7947582e-10, 2.8669328e-06, 1.9824435e-03, 4.0190176e-07,\n",
       "        9.9341971e-01, 4.5945863e-03],\n",
       "       [9.9678254e-01, 2.6651747e-03, 5.4198767e-07, 4.5304492e-04,\n",
       "        2.1355992e-05, 7.7215132e-05],\n",
       "       [4.0174092e-14, 8.7521236e-08, 4.2656190e-10, 9.9996984e-01,\n",
       "        2.0113630e-08, 3.0039000e-05],\n",
       "       [2.5032939e-06, 9.9980289e-01, 2.4989599e-06, 1.5027422e-04,\n",
       "        2.8892080e-05, 1.2937711e-05],\n",
       "       [9.9903357e-01, 8.0203736e-04, 6.7818846e-08, 1.3396253e-04,\n",
       "        4.4031231e-06, 2.5973213e-05],\n",
       "       [1.3452083e-09, 2.5998891e-06, 1.7271938e-02, 2.1089558e-07,\n",
       "        9.8226142e-01, 4.6375583e-04],\n",
       "       [7.8406372e-16, 1.2811016e-09, 1.0624502e-11, 9.9998307e-01,\n",
       "        2.8746545e-09, 1.6962389e-05],\n",
       "       [9.9819881e-01, 1.4712779e-03, 2.0104804e-07, 2.7384743e-04,\n",
       "        1.0067354e-05, 4.5779037e-05],\n",
       "       [9.0575469e-15, 1.9701895e-11, 1.9089896e-06, 4.8297716e-07,\n",
       "        2.9835892e-03, 9.9701405e-01],\n",
       "       [5.0715943e-10, 1.1989487e-06, 2.2773684e-03, 6.8943331e-07,\n",
       "        9.9119765e-01, 6.5230494e-03],\n",
       "       [2.4253308e-10, 9.2712526e-07, 1.4782221e-03, 7.6321817e-07,\n",
       "        9.8770708e-01, 1.0812949e-02],\n",
       "       [1.9536481e-05, 9.9598014e-01, 6.0180185e-04, 4.1243603e-04,\n",
       "        2.6568943e-03, 3.2915885e-04],\n",
       "       [1.8566244e-11, 2.4760982e-07, 7.2208741e-06, 3.5529124e-04,\n",
       "        3.2671851e-03, 9.9637008e-01],\n",
       "       [5.0986923e-06, 9.9962127e-01, 3.1448687e-07, 3.6299214e-04,\n",
       "        4.9510063e-06, 5.4415800e-06],\n",
       "       [3.0815420e-10, 9.5126018e-07, 1.9539285e-03, 1.1041885e-06,\n",
       "        9.8841023e-01, 9.6337711e-03],\n",
       "       [6.5717424e-14, 1.0549125e-07, 1.0711562e-09, 9.9995458e-01,\n",
       "        3.5572025e-08, 4.5311965e-05],\n",
       "       [7.4603100e-05, 9.8431039e-01, 2.5427868e-04, 1.2028366e-02,\n",
       "        2.4674097e-03, 8.6485385e-04],\n",
       "       [1.1831240e-13, 2.5206412e-10, 6.2392212e-07, 3.7170281e-05,\n",
       "        4.4299118e-04, 9.9951923e-01],\n",
       "       [3.3367878e-11, 2.5028251e-06, 3.9408815e-06, 9.9163228e-01,\n",
       "        2.3800716e-05, 8.3375210e-03],\n",
       "       [4.3463958e-15, 6.3219501e-09, 1.0304775e-10, 9.9986076e-01,\n",
       "        2.0753047e-08, 1.3915250e-04],\n",
       "       [9.3192809e-16, 3.7317798e-14, 1.5470605e-05, 4.6137846e-08,\n",
       "        2.6690675e-04, 9.9971753e-01],\n",
       "       [1.7953847e-09, 2.9215995e-05, 2.0078682e-04, 3.6851875e-04,\n",
       "        2.9079041e-01, 7.0861113e-01],\n",
       "       [1.5658515e-10, 2.2948591e-07, 9.9951363e-01, 4.7735665e-10,\n",
       "        4.5621212e-04, 2.9893979e-05],\n",
       "       [5.2942795e-10, 3.2950177e-06, 9.1106171e-04, 3.5342591e-06,\n",
       "        9.3697071e-01, 6.2111355e-02],\n",
       "       [7.3162423e-09, 6.0655611e-06, 9.8626745e-01, 7.2384294e-09,\n",
       "        1.3626958e-02, 9.9484489e-05],\n",
       "       [6.0687576e-05, 9.9956483e-01, 8.4760513e-06, 2.2636897e-04,\n",
       "        9.9174067e-05, 4.0502626e-05],\n",
       "       [5.6597908e-14, 1.6556843e-08, 6.2682132e-10, 9.9994028e-01,\n",
       "        5.4075841e-08, 5.9660546e-05],\n",
       "       [3.6568979e-13, 9.5736385e-10, 9.2579994e-06, 2.5857519e-06,\n",
       "        1.7162891e-02, 9.8282522e-01],\n",
       "       [9.9808973e-01, 1.5480150e-03, 1.9164231e-07, 3.0591476e-04,\n",
       "        9.8795708e-06, 4.6153153e-05],\n",
       "       [2.0576334e-12, 3.0127609e-11, 2.9081121e-02, 1.1308496e-07,\n",
       "        2.2973051e-02, 9.4794577e-01]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7d000fb-6706-42c8-823e-4d46bb588dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[np.argmax(i) for i in y_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0225e3ae-eddd-4ab9-807e-8439832a9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8155fc0f-8eaf-436c-8f89-af39c7ff10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=tf.math.confusion_matrix(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8f67061-b2df-4039-a80a-1bd2115b0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "798f186f-baa3-43d0-8722-c45710fd5090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhD0lEQVR4nO3dfXRU1f3v8c/wNFBIRggEEikQBQ3hWUCagiAP1XKRCr3VQvFXxC6tGMGYBWrurxqxrYO2C9FiUfEW8K4i+muLWh9wpahQFiBJEAQfgAgFRCCgbQL5yYCZc/+Ya3pnJwITzsw5nPN+dZ21mjNhn+/ssvrl+937nBOwLMsSAADwjWZOBwAAAFKL5A8AgM+Q/AEA8BmSPwAAPkPyBwDAZ0j+AAD4DMkfAACfIfkDAOAzJH8AAHymhdMBfG1X7+87HYIr5H2y3ekQAMD1vjp1MKnjnz62x7axWna8xLax7OKa5A8AgGtE65yOIKlo+wMA4DNU/gAAmKyo0xEkFckfAABTlOQPAICvWB6v/FnzBwDAZ6j8AQAw0fYHAMBnaPsDAAAvofIHAMDk8Yf8kPwBADDR9gcAAF5C5Q8AgInd/gAA+AsP+QEAAJ5C5Q8AgIm2PwAAPuPxtj/JHwAAk8fv82fNHwAAn6HyBwDARNsfAACf8fiGP9r+AAD4DJU/AAAm2v4AAPgMbX9va5GZoS6P3KNLN76onu+9rO4vL1awTy+nw3LEzNunq3LXJp2o+UQb1v9VQ4cMdDokxzAXMcxDDPMQwzx4h6+Tf7P0dvr2igWyvvpKB2/7hf5x3W06+sgSRWtOOB1ayt1www/029+U6Je/WqChw76vbe9/qNdf+6M6dcpwOrSUYy5imIcY5iHGb/NgWXW2HW4UsCzLcjoISdrV+/spv2bHohlqPaiPPv2POSm/9jfJ+2S7I9fdsP6vKivfprsKfyFJCgQC+seeMj35+6V69DdPOhKTU5iLGOYhhnmIcds8fHXqYFLHP7n1VdvGaj3wOtvGskvClf+xY8f06KOPavLkycrPz1d+fr4mT56s3/zmNzp69GgyYkyatqO/o8gHu5T12H/qkvUr1e3PixS6IfX/CHFay5YtdcUV/bXmrb/Xn7MsS2veWq/vfGewg5GlHnMRwzzEMA8xzIP3JJT8y8rKdNlll+mJJ55QKBTSyJEjNXLkSIVCIT3xxBPKzc1VeXn5WceJRCKqqamJO045sLmi5bezFJpynU7tO6iDt/6nqle+pk7/a6bSrx+X8lic1LFjB7Vo0UJVR47Fna+qOqounTs5FJUzmIsY5iGGeYjx5TxEo/YdCVi3bp0mTpyo7OxsBQIBvfTSS3GfW5alBx54QFlZWWrTpo3GjRun3bt3J/z1EtrtP2vWLN1www166qmnFAgEGgR0++23a9asWdq4ceMZxwmHw5o3b17cuTszLtWsTj0TCee8BQIBnfxgtz5fuEySFPnoE7Xq1UOhKRNU8/LfUhoLAMBFHLrVr7a2VgMGDNAtt9yiH/7whw0+f/TRR/XEE09o+fLlysnJ0f33369rr71WH374oVq3bn3O10ko+W/btk3Lli1rkPilWCK9++67NWjQoLOOU1xcrKKiorhz+4f+KJFQbPHVsS906pP9cedO7dmvtGuGpzwWJx079oW++uorZXbuGHc+M7OTDh+5sJZyzhdzEcM8xDAPMb6cB4de7DN+/HiNHz++0c8sy9LChQv1i1/8Qtdff70k6bnnnlPnzp310ksvacqUKed8nYTa/l26dNHmzZu/8fPNmzerc+fOZx0nGAwqPT097mjVLPU3Hny55UO17NE17lyrHhfr9GdVKY/FSadPn9aWLe9rzOgR9ecCgYDGjB6hTZsqHIws9ZiLGOYhhnmIYR7OT2NL3ZFIJOFx9u7dq8OHD2vcuH8vTYdCIQ0bNuysHXdTQpX/nDlzdNttt6miokJjx46tT/RHjhzRmjVrtGTJEv32t79NKAAn/XP5KnVbsUAdbvuxjq9ep9b9Llfohv+hIyWPOx1ayj32+BIt/d+PqWLL+yore0+zZ92qtm3baNnyF5wOLeWYixjmIYZ5iPHdPNjY9m9sqbukpEQPPvhgQuMcPnxYkhoU2Z07d67/7FwllPwLCgrUsWNHPfbYY/r973+vurpYW6R58+YaPHiwli1bphtvvDGhAJwU2bFLn81+SB3vnqEOd0zT6U8P6+j8p3T81bedDi3l/uu/XlGnjh304ANz1KVLJ23b9oEmXHeTqqqOnf0PewxzEcM8xDAPMb6bBxs3oTe21B0MBm0bvymafJ//6dOndexY7H/0jh07qmXLlucViBP3+buRU/f5A8CFJOn3+W+yr6PR+js/btKfCwQCWrVqlSZNmiRJ2rNnjy699FK99957GjhwYP3vjRo1SgMHDtTjj59717rJC+0tW7ZUVlaWsrKyzjvxAwDgKlbUvsMmOTk56tKli9asWVN/rqamRu+++67y8/MTGosX+wAAYHLoxT4nTpxQZWVl/c979+7V1q1b1aFDB3Xr1k2FhYX61a9+pV69etXf6pednV3fHThXJH8AAFyivLxco0ePrv/5670C06dP17Jly3TPPfeotrZWt912m/71r39pxIgRWr16dUL3+Es+f7a/G7HmDwBnl/Q1/7//H9vGan3Vf9g2ll2o/AEAMLj1bXx28fUrfQEA8CMqfwAATA5t+EsVkj8AACaHXuyTKiR/AABMHq/8WfMHAMBnqPwBADDR9gcAwGdo+wMAAC+h8gcAwETbHwAAn6HtDwAAvITKHwAAk8crf5I/AAAmj6/50/YHAMBnqPwBADDR9gcAwGc83vYn+QMAYPJ45c+aPwAAPkPlDwCAibY/AAA+4/G2v2uSf94n250OwRWqJvR0OgRXyHyt0ukQAMCzXJP8AQBwDSp/AAB8xrKcjiCp2O0PAIDPUPkDAGCi7Q8AgM94PPnT9gcAwGeo/AEAMPGQHwAAfMbjbX+SPwAAJm71AwAAXkLlDwCAibY/AAA+4/HkT9sfAACfofIHAMDErX4AAPiLFWW3PwAA8BAqfwAATB7f8EfyBwDA5PE1f9r+AAD4DJU/AAAmj2/4I/kDAGBizR8AAJ/xePJnzR8AAJ+h8gcAwOTxV/qS/AEAMNH2BwAAXkLlDwCAiVv9AADwGZ7wBwAAvMT25H/gwAHdcsstZ/ydSCSimpqauMPy+M5KAMAFJGrZd7iQ7cn/iy++0PLly8/4O+FwWKFQKO6wosftDgUAgCaxolHbDjdKeM3/lVdeOePne/bsOesYxcXFKioqijvXPiM30VAAAEATJJz8J02apEAgcMY2fSAQOOMYwWBQwWAwoT8DAEDKuLRdb5eE2/5ZWVn6y1/+omg02uixZcuWZMQJAEDqWFH7DhdKOPkPHjxYFRUV3/j52boCAAC4nkMb/urq6nT//fcrJydHbdq00aWXXqpf/vKXtufVhNv+c+fOVW1t7Td+3rNnT7399tvnFRQAAH70yCOPaPHixVq+fLn69Omj8vJyzZgxQ6FQSLNnz7btOgkn/6uuuuqMn7dt21ajRo1qckAAADjOoV36GzZs0PXXX68JEyZIknr06KHnn39emzdvtvU6POQHAACTjW3/xp5tE4lEGr3sd7/7Xa1Zs0a7du2SJG3btk3r16/X+PHjbf16JH8AAJKosWfbhMPhRn/3vvvu05QpU5Sbm6uWLVtq0KBBKiws1LRp02yNiWf7AwBgsnGXfmPPtjFvd//aiy++qD/+8Y9asWKF+vTpo61bt6qwsFDZ2dmaPn26bTGR/AEAMNl4n39jz7b5JnPnzq2v/iWpX79+2rdvn8LhsK3Jn7Y/AAAu8d///d9q1iw+NTdv3lxRmzcgUvkDAGBw6pn8EydO1K9//Wt169ZNffr00XvvvacFCxac9YV5iSL5AwBgcujxvr/73e90//3364477lBVVZWys7P185//XA888ICt1yH5AwDgEmlpaVq4cKEWLlyY1OuQ/AEAMHn8xT4kfwAATC59IY9dSP4AAJg8Xvlzqx8AAD5D5Q8AgMHyeOVP8gcAwOTx5E/bHwAAn6HyBwDA5NAT/lKF5A8AgIm2PwAA8BIqfwAATB6v/En+AAAYLMvbyZ+2PwAAPkPlDwCAibY/AAA+Q/IHAMBfeLwvUirztUqnQ3CFqgk9nQ7BFfj7ACAZSP4AAJio/AEA8BlvP92XW/0AAPAbKn8AAAxs+AMAwG88nvxp+wMA4DNU/gAAmDy+4Y/kDwCAwetr/rT9AQDwGSp/AABMtP0BAPAXr7f9Sf4AAJg8Xvmz5g8AgM9Q+QMAYLA8XvmT/AEAMHk8+dP2BwDAZ6j8AQAw0PYHAMBvPJ78afsDAOAzVP4AABho+wMA4DMkfwAAfMbryZ81fwAAfIbKHwAAkxVwOoKkIvkDAGCg7Q8AADyFyh8AAIMVpe0PAICv0PY3fPnll1q/fr0+/PDDBp+dPHlSzz33nC2BAQCA5Ego+e/atUu9e/fWyJEj1a9fP40aNUqHDh2q/7y6ulozZsw46ziRSEQ1NTVxh2VZiUcPAEASWFbAtsONEkr+9957r/r27auqqirt3LlTaWlpGj58uPbv35/QRcPhsEKhUNxhRY8nNAYAAMliRe073ChgJVByd+7cWX/729/Ur18/SZJlWbrjjjv0+uuv6+2331bbtm2VnZ2turq6M44TiUQUiUTizrXPyFUg4M5/ISH1qib0dDoEV8h8rdLpEABX+urUwaSO/+mwMbaN1fXdt2wbyy4JVf5ffvmlWrT49x7BQCCgxYsXa+LEiRo1apR27dp1TuMEg0Glp6fHHSR+AIBbWNGAbYcbJbTbPzc3V+Xl5erdu3fc+UWLFkmSfvCDH9gXGQAADvH6NrSEKv/Jkyfr+eefb/SzRYsWaerUqWzcAwBc8Lxe+Se05p9MLVpd7HQIcBHW/GNY8wcal+w1/31XjLNtrO5b/mbbWHbhIT8AABjcWrHbheQPAIDBHT3x5OHFPgAA+AyVPwAABq+3/an8AQAwOPl434MHD+qmm25SRkaG2rRpo379+qm8vNzW70flDwCAS/zzn//U8OHDNXr0aL3xxhvq1KmTdu/erfbt29t6HZI/AAAGp57J/8gjj+jb3/62li5dWn8uJyfH9uvQ9gcAwBC1ArYdjb3J1ny/zddeeeUVDRkyRDfccIMyMzM1aNAgLVmyxPbvR/IHACCJGnuTbTgcbvR39+zZo8WLF6tXr1568803NXPmTM2ePVvLly+3NSae8AdX4gl/MTzhD2hcsp/wtzN3vG1j9dj2UoNKPxgMKhgMNvjdVq1aaciQIdqwYUP9udmzZ6usrEwbN260LSbW/AEAMNh5q983JfrGZGVlKS8vL+5c79699ec//9m2eCSSPwAADTjVEx8+fLh27twZd27Xrl3q3r27rddhzR8AAJe4++67tWnTJj388MOqrKzUihUr9Mwzz6igoMDW61D5AwBgcOoJf0OHDtWqVatUXFyshx56SDk5OVq4cKGmTZtm63VI/gAAGKJNeDKfXa677jpdd911Sb0GbX8AAHyGyh8AAENTnsl/ISH5AwBgcMcTcJKHtj8AAD5D5Q8AgMHJDX+pQPIHAMDg9TV/2v4AAPgMlT8AAAavb/gj+QMAYGDNH3AAr7KN4dXGMfx9QKqx5g8AADyFyh8AAANtfwAAfMbj+/1o+wMA4DdU/gAAGGj7AwDgM+z2BwAAnkLlDwCAIep0AElG8gcAwGCJtj8AAPAQKn8AAAxRj9/oT/IHAMAQ9Xjbn+QPAICBNX8AAOApVP4AABi41Q8AAJ+h7Q8AADyFyh8AAANtfwAAfMbryZ+2PwAAPkPlDwCAwesb/kj+AAAYot7O/bT9AQDwGyp/AAAMPNsfAACf8fhL/Uj+AACYuNUPAAB4CpU/AACGaIA1fwAAfIU1f8NHH32kTZs2KT8/X7m5ufr444/1+OOPKxKJ6KabbtKYMWPOOkYkElEkEok7Z1mWAh7/lxYAAG6Q0Jr/6tWrNXDgQM2ZM0eDBg3S6tWrNXLkSFVWVmrfvn265ppr9NZbb511nHA4rFAoFHdY0eNN/hIAANgpauPhRgkl/4ceekhz587V559/rqVLl+onP/mJbr31VpWWlmrNmjWaO3eu5s+ff9ZxiouLVV1dHXcEmqU1+UsAAGCnaMC+w40SSv4ffPCBbr75ZknSjTfeqOPHj+tHP/pR/efTpk3T+++/f9ZxgsGg0tPT4w5a/gAApEbCa/5fJ+lmzZqpdevWCoVC9Z+lpaWpurravugAAHCA15/wl1Dl36NHD+3evbv+540bN6pbt271P+/fv19ZWVn2RQcAgAMsGw83Sqjynzlzpurq6up/7tu3b9znb7zxxjnt9gcAAM5JKPnffvvtZ/z84YcfPq9gAABwA7du1LMLD/kBAMDg1lv07ELyBwDA4Na1ervwYh8AAHyGyh8AAANr/gAA+IzX1/xp+wMA4DNU/gAAGLxe+ZP8AQAwWB5f86ftDwCAz5D8AQAwRG08mmr+/PkKBAIqLCw8j1EaR9sfAACD02v+ZWVlevrpp9W/f/+kjE/lDwCAi5w4cULTpk3TkiVL1L59+6Rcg+QPAIDBzlf6RiIR1dTUxB2RSOQbr11QUKAJEyZo3Lhxyfp6JH8AAEzRgH1HOBxWKBSKO8LhcKPXXblypbZs2fKNn9uFNX8AAAx2rvkXFxerqKgo7lwwGGzwewcOHNBdd92l0tJStW7d2sYIGiL5AwCQRMFgsNFkb6qoqFBVVZWuuOKK+nN1dXVat26dFi1apEgkoubNm9sSE8kfAACDE7v9x44dq+3bt8edmzFjhnJzc3Xvvffalvglkj8AAA1YDlwzLS1Nffv2jTvXtm1bZWRkNDh/vtjwBwCAz1D5AwBgiLrk2f7vvPNOUsYl+QMAYHD6CX/JRtsfAACfofIHAMDgxIa/VCL5AwBgiHo8/ZP8ARfLfK3S6RBcoWpCT6dDcAX+PsAuJH8AAAxe3/BH8gcAwODtpj/JHwCABrxe+XOrHwAAPkPlDwCAwS1P+EsWkj8AAAav3+pH2x8AAJ+h8gcAwODtup/kDwBAA+z2BwAAnkLlDwCAwesb/kj+AAAYvJ36afsDAOA7VP4AABi8vuGP5A8AgIE1fwAAfMbbqZ81fwAAfIfKHwAAA2v+AAD4jOXxxj9tfwAAfIbKHwAAA21/AAB8xuu3+tH2BwDAZ6j8AQAweLvuJ/kDANAAbX8AAOApVP4AABjY7X8OLMtSIBCwYygAABzHQ37OQTAY1EcffWTHUAAAOC5q4+FGCVX+RUVFjZ6vq6vT/PnzlZGRIUlasGDBGceJRCKKRCJx5+geAACQGgkl/4ULF2rAgAG66KKL4s5blqWPPvpIbdu2PacEHg6HNW/evLhzgWbtFGienkg4AAAkhdfb/gHLss75G86fP1/PPPOMnn32WY0ZM6b+fMuWLbVt2zbl5eWd0ziNVf7tM3Kp/AE0qmpCT6dDcIXM1yqdDsE1vjp1MKnjT+/xP20ba/k//mzbWHZJaM3/vvvu0wsvvKCZM2dqzpw5On36dJMuGgwGlZ6eHneQ+AEASI2EN/wNHTpUFRUVOnr0qIYMGaIdO3aQuAEAnhK1LNsON2rSrX7t2rXT8uXLtXLlSo0bN051dXV2xwUAgGPcmbLtc173+U+ZMkUjRoxQRUWFunfvbldMAAAgic77IT9du3ZV165d7YgFAABX8Pqz/Xm8LwAABq/f6seLfQAA8BkqfwAADG59LK9dSP4AABhY8wcAwGdY8wcAAJ5C5Q8AgIE1fwAAfCaBd95dkGj7AwDgM1T+AAAY2O0PAIDPeH3Nn7Y/AAA+Q+UPAIDB6/f5k/wBADB4fc2ftj8AAC4RDoc1dOhQpaWlKTMzU5MmTdLOnTttvw7JHwAAg2VZth2JWLt2rQoKCrRp0yaVlpbq9OnTuuaaa1RbW2vr96PtDwCAwand/qtXr477edmyZcrMzFRFRYVGjhxp23VI/gAAGOzc8BeJRBSJROLOBYNBBYPBs/7Z6upqSVKHDh1si0ei7Q8AQFKFw2GFQqG4IxwOn/XPRaNRFRYWavjw4erbt6+tMVH5AwBgsHO3f3FxsYqKiuLOnUvVX1BQoB07dmj9+vW2xfI1kj8AAAY7X+xzri3+/9+dd96pV199VevWrVPXrl1ti+VrJH8AAFzCsizNmjVLq1at0jvvvKOcnJykXIfkDwCAwamH/BQUFGjFihV6+eWXlZaWpsOHD0uSQqGQ2rRpY9t12PAHAIDBsvE/iVi8eLGqq6t19dVXKysrq/544YUXbP1+VP4AXC/ztUqnQ3CFLz/7u9MhIMns3GtwJiR/AAAM0RQlYaeQ/AEAMHg79bPmDwCA71D5AwBg8PorfUn+AAAYSP4AAPhMqnbdO4U1fwAAfIbKHwAAA21/AAB8JtEn811oaPsDAOAzVP4AABi8vuGP5A8AgMHra/60/QEA8BkqfwAADLT9AQDwGdr+AADAU6j8AQAweP0+f5I/AACGKGv+AAD4i9crf9b8AQDwGSp/AAAMtP0BAPAZ2v4AAMBTqPwBADDQ9gcAwGdo+wMAAE+h8gcAwEDbHwAAn/F62/+8kn9tba1efPFFVVZWKisrS1OnTlVGRsZZ/1wkElEkEok7Z1mWAoHA+YQDAADOQUJr/nl5efriiy8kSQcOHFDfvn119913q7S0VCUlJcrLy9PevXvPOk44HFYoFIo7rOjxpn0DAABsZllR2w43CljWuS9sNGvWTIcPH1ZmZqZuuukm7d27V6+//rpCoZBOnDihyZMnq1OnTlqxYsUZx2ms8m+fkUvlDwBn8OVnf3c6BNdo2fGSpI7fPaO/bWPt+/x928ayS5Pb/hs3btRTTz2lUCgkSWrXrp3mzZunKVOmnPXPBoNBBYPBuHMkfgCAWyRQF1+QEr7V7+skffLkSWVlZcV9dvHFF+vo0aP2RAYAAJIi4cp/7NixatGihWpqarRz50717du3/rN9+/ad04Y/AADcLMpu/38rKSmJ+7ldu3ZxP//1r3/VVVdddf5RAQDgIK+3/RPa8JdMLVpd7HQIAOBqbPj7t2Rv+Lu4fR/bxjr4zw9sG8suPOQHAAADT/gDAMBnvP6EP17sAwCAz1D5AwBgcMl2uKQh+QMAYPD6rX60/QEA8BkqfwAADLT9AQDwGW71AwDAZ7xe+bPmDwCAz1D5AwBg8Ppuf5I/AAAG2v4AAMBTqPwBADCw2x8AAJ/hxT4AAMBTqPwBADDQ9gcAwGfY7Q8AADyFyh8AAAMb/gAA8BnLsmw7EvXkk0+qR48eat26tYYNG6bNmzfb/v1I/gAAGJxK/i+88IKKiopUUlKiLVu2aMCAAbr22mtVVVVl6/cj+QMA4BILFizQrbfeqhkzZigvL09PPfWUvvWtb+kPf/iDrdch+QMAYLBsPCKRiGpqauKOSCTS4JqnTp1SRUWFxo0bV3+uWbNmGjdunDZu3GjzF4RlWZZ18uRJq6SkxDp58qTToTiKeYhhHmKYhxjmIYZ5aJqSkpIG/yYoKSlp8HsHDx60JFkbNmyIOz937lzryiuvtDWmgGV5/GbGc1RTU6NQKKTq6mqlp6c7HY5jmIcY5iGGeYhhHmKYh6aJRCINKv1gMKhgMBh37rPPPtPFF1+sDRs2KD8/v/78Pffco7Vr1+rdd9+1LSZu9QMAIIkaS/SN6dixo5o3b64jR47EnT9y5Ii6dOlia0ys+QMA4AKtWrXS4MGDtWbNmvpz0WhUa9asiesE2IHKHwAAlygqKtL06dM1ZMgQXXnllVq4cKFqa2s1Y8YMW69D8v9/gsGgSkpKzqk142XMQwzzEMM8xDAPMcxD8v34xz/W0aNH9cADD+jw4cMaOHCgVq9erc6dO9t6HTb8AQDgM6z5AwDgMyR/AAB8huQPAIDPkPwBAPAZkr9S8/pEt1u3bp0mTpyo7OxsBQIBvfTSS06H5IhwOKyhQ4cqLS1NmZmZmjRpknbu3Ol0WCm3ePFi9e/fX+np6UpPT1d+fr7eeOMNp8Ny3Pz58xUIBFRYWOh0KCn14IMPKhAIxB25ublOh4Xz4Pvkn6rXJ7pdbW2tBgwYoCeffNLpUBy1du1aFRQUaNOmTSotLdXp06d1zTXXqLa21unQUqpr166aP3++KioqVF5erjFjxuj666/XBx984HRojikrK9PTTz+t/v37Ox2KI/r06aNDhw7VH+vXr3c6JJwPW98UcAG68sorrYKCgvqf6+rqrOzsbCscDjsYlbMkWatWrXI6DFeoqqqyJFlr1651OhTHtW/f3nr22WedDsMRx48ft3r16mWVlpZao0aNsu666y6nQ0qpkpISa8CAAU6HARv5uvJP6esTcUGqrq6WJHXo0MHhSJxTV1enlStXqra21vZHjF4oCgoKNGHChLj/r/Cb3bt3Kzs7W5dccommTZum/fv3Ox0SzoOvn/B37Ngx1dXVNXhyUufOnfXxxx87FBXcIhqNqrCwUMOHD1ffvn2dDifltm/frvz8fJ08eVLt2rXTqlWrlJeX53RYKbdy5Upt2bJFZWVlTofimGHDhmnZsmW6/PLLdejQIc2bN09XXXWVduzYobS0NKfDQxP4OvkDZ1JQUKAdO3b4dm3z8ssv19atW1VdXa0//elPmj59utauXeurfwAcOHBAd911l0pLS9W6dWunw3HM+PHj6/97//79NWzYMHXv3l0vvviifvaznzkYGZrK18k/la9PxIXlzjvv1Kuvvqp169apa9euTofjiFatWqlnz56SpMGDB6usrEyPP/64nn76aYcjS52KigpVVVXpiiuuqD9XV1endevWadGiRYpEImrevLmDETrjoosu0mWXXabKykqnQ0ET+XrNP5WvT8SFwbIs3XnnnVq1apXeeust5eTkOB2Sa0SjUUUiEafDSKmxY8dq+/bt2rp1a/0xZMgQTZs2TVu3bvVl4pekEydO6JNPPlFWVpbToaCJfF35S6l7faLbnThxIu5f8Xv37tXWrVvVoUMHdevWzcHIUqugoEArVqzQyy+/rLS0NB0+fFiSFAqF1KZNG4ejS53i4mKNHz9e3bp10/Hjx7VixQq98847evPNN50OLaXS0tIa7Pdo27atMjIyfLUPZM6cOZo4caK6d++uzz77TCUlJWrevLmmTp3qdGhoIt8n/1S9PtHtysvLNXr06Pqfi4qKJEnTp0/XsmXLHIoq9RYvXixJuvrqq+POL126VDfffHPqA3JIVVWVfvrTn+rQoUMKhULq37+/3nzzTX3ve99zOjQ44NNPP9XUqVP1+eefq1OnThoxYoQ2bdqkTp06OR0amohX+gIA4DO+XvMHAMCPSP4AAPgMyR8AAJ8h+QMA4DMkfwAAfIbkDwCAz5D8AQDwGZI/AAA+Q/IHAMBnSP4AAPgMyR8AAJ8h+QMA4DP/FxPBTP8D3YcUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot=heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16c81da7-8fa8-41fa-b57d-1a54fba07b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot.get_figure().savefig('v2_cm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e7eec04-27ac-416a-aae9-8f03bfbd4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         7\n",
      "           5       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae02e70f-ba37-48e7-a4ae-070d58a624d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new=keras.models.load_model('my_best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60ef3aba-1efb-461e-b465-89364303a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save('new_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8642b09-c1e3-406a-bcc9-f55fe2186e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
